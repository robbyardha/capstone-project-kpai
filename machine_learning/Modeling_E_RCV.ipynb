{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modeling E-RCV.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ2kHzd513xz"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Flatten, LSTM\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.merge import Concatenate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cex97mqD3EFA",
        "outputId": "ad900e75-9b10-4bc1-f383-776320442f99"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZU3NqI13T9W",
        "outputId": "f0d3d9d0-023c-4f93-9bd7-7c4923952aad"
      },
      "source": [
        "!ls \"/content/drive/MyDrive/E-RCV\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Alodokter - Alodokter.csv'   combined_slang_words.txt\t glove.6B.100d.txt\n",
            " clean_data.csv\t\t      combined_stop_words.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVZWj5tr3cQE"
      },
      "source": [
        "curhat = pd.read_csv(\"/content/drive/MyDrive/E-RCV/clean_data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "N_em4-t75Y_1",
        "outputId": "47754183-07d6-4c66-8549-3cd00e27ec0d"
      },
      "source": [
        "print(curhat.shape)\n",
        "\n",
        "curhat.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1342, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Curhat</th>\n",
              "      <th>Judul</th>\n",
              "      <th>Link</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Keluarga</th>\n",
              "      <th>Percintaan</th>\n",
              "      <th>Anak Remaja</th>\n",
              "      <th>Pengembangan Diri</th>\n",
              "      <th>Trauma</th>\n",
              "      <th>Phobia</th>\n",
              "      <th>Masalah Emosi</th>\n",
              "      <th>Bullying</th>\n",
              "      <th>Bukan Psikologi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sore dok nama naomi menghilangkan trauma kecil...</td>\n",
              "      <td>Trauma masa kecil tentang bully</td>\n",
              "      <td>https://www.alodokter.com/komunitas/topic/trau...</td>\n",
              "      <td>Trauma</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>selamat malam dok melakukan operasi benjolan d...</td>\n",
              "      <td>gatal dan bengkak pada bekas luka operasi</td>\n",
              "      <td>https://www.alodokter.com/komunitas/topic/gata...</td>\n",
              "      <td>Trauma</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>selamat sore dok jatuh ketingian 4meter sedaka...</td>\n",
              "      <td>Solusi atasi ngilu pada kaki setelah terjatuh ...</td>\n",
              "      <td>https://www.alodokter.com/komunitas/topic/apa-...</td>\n",
              "      <td>Trauma</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dok habis jatuh motor badan dok selang 4jam ha...</td>\n",
              "      <td>Penyebab anus terasa sakit setelah terjatuh da...</td>\n",
              "      <td>https://www.alodokter.com/komunitas/topic/apa-...</td>\n",
              "      <td>Trauma</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>selamat siang dok gini dok tenggorokan gusi 3 ...</td>\n",
              "      <td>Tenggorokan dan gusi disebelah kanan sakit</td>\n",
              "      <td>https://www.alodokter.com/komunitas/topic/teng...</td>\n",
              "      <td>Trauma</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Curhat  ... Bukan Psikologi\n",
              "0  sore dok nama naomi menghilangkan trauma kecil...  ...             0.0\n",
              "1  selamat malam dok melakukan operasi benjolan d...  ...             1.0\n",
              "2  selamat sore dok jatuh ketingian 4meter sedaka...  ...             1.0\n",
              "3  dok habis jatuh motor badan dok selang 4jam ha...  ...             1.0\n",
              "4  selamat siang dok gini dok tenggorokan gusi 3 ...  ...             1.0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIMtf3F35pVd"
      },
      "source": [
        "filter = curhat[\"Curhat\"] != \"\"\n",
        "curhat = curhat[filter]\n",
        "curhat = curhat.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXVkkbfk5uRt",
        "outputId": "8f4f140b-760e-466e-d676-4f9f6d4ac4fe"
      },
      "source": [
        "print(curhat[\"Curhat\"][108])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "assallammualaikum wr wbselamat malam dok dok kakak bola matanya keluar matanya merah susah berkomunikasi susah menangkap lakukan rayu makan lain-lain dokter disini keadaan kesehatannya dok sehat darah dllnya normal dok gejala sakau iya dok kakak kenal narkotika, psikotropika, obat terlarang teman nya ketangkep garagara pemilik barang sabu sabu dok mohon penjelasannya dokterimakasih wassallammualaikum wr wb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmS09B-p52Of",
        "outputId": "6d2f1fb6-da53-4f12-e689-40065a6a7b8a"
      },
      "source": [
        "print(\"keluarga:\" + str(curhat[\"Keluarga\"][108]))\n",
        "print(\"percintaan:\" + str(curhat[\"Percintaan\"][108]))\n",
        "print(\"anak remaja:\" + str(curhat[\"Anak Remaja\"][108]))\n",
        "print(\"pengembangan diri:\" + str(curhat[\"Pengembangan Diri\"][108]))\n",
        "print(\"trauma:\" + str(curhat[\"Trauma\"][108]))\n",
        "print(\"phobia:\" + str(curhat[\"Phobia\"][108]))\n",
        "print(\"masalah emosi:\" + str(curhat[\"Masalah Emosi\"][108]))\n",
        "print(\"bullying:\" + str(curhat[\"Bullying\"][108]))\n",
        "print(\"bukan psikologi:\" + str(curhat[\"Bukan Psikologi\"][108]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keluarga:0.0\n",
            "percintaan:0.0\n",
            "anak remaja:0.0\n",
            "pengembangan diri:0.0\n",
            "trauma:0.0\n",
            "phobia:0.0\n",
            "masalah emosi:0.0\n",
            "bullying:0.0\n",
            "bukan psikologi:1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Su6mcjS157fr",
        "outputId": "722f12ac-b209-4692-d224-c6abce520ed5"
      },
      "source": [
        "curhat_labels = curhat[[\"Keluarga\", \"Percintaan\", \"Anak Remaja\", \"Pengembangan Diri\", \"Trauma\", \"Phobia\", \"Masalah Emosi\", \"Bullying\", \"Bukan Psikologi\"]]\n",
        "curhat_labels.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Keluarga</th>\n",
              "      <th>Percintaan</th>\n",
              "      <th>Anak Remaja</th>\n",
              "      <th>Pengembangan Diri</th>\n",
              "      <th>Trauma</th>\n",
              "      <th>Phobia</th>\n",
              "      <th>Masalah Emosi</th>\n",
              "      <th>Bullying</th>\n",
              "      <th>Bukan Psikologi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Keluarga  Percintaan  Anak Remaja  ...  Masalah Emosi  Bullying  Bukan Psikologi\n",
              "0       0.0         0.0          1.0  ...            1.0       1.0              0.0\n",
              "1       0.0         0.0          0.0  ...            0.0       0.0              1.0\n",
              "2       0.0         0.0          0.0  ...            0.0       0.0              1.0\n",
              "3       0.0         0.0          0.0  ...            0.0       0.0              1.0\n",
              "4       0.0         0.0          0.0  ...            0.0       0.0              1.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "AV0fA7is6Amj",
        "outputId": "85e6dc47-0dae-473d-9b47-894b34e9eb37"
      },
      "source": [
        "fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "fig_size[0] = 8\n",
        "fig_size[1] = 6\n",
        "plt.rcParams[\"figure.figsize\"] = fig_size\n",
        "\n",
        "curhat_labels.sum(axis=0).plot.bar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff02bc59a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAG+CAYAAABGTqdVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7xtZV3v8c+Xm6AmiGwJuQgmReQFcGuYZilHk1AhL3jBIA8d8uQ1PRmnzjneOoVamVpRHNHAvKGloKKB5C0NdSMIKJhbhABBtje8oAT4O3+MsdxzL9ZmXfZaazxj7s/79VqvNceYc635m7DX/M5njGf8nlQVkiSpDdsMXYAkSdrIYJYkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhqy3dAFAOy222617777Dl2GJEmr4oILLvhGVa2Z674mgnnfffdl3bp1Q5chSdKqSHLV5u7zULYkSQ0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIYYzJIkNcRgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGNLHsoyRNm31P/MCKP8eVJx2x4s+h1eeIWZKkhhjMkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIYYzJIkNcRgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGzBvMSX4uyUUTX99N8sIkuyY5N8mX++937x+fJK9Psj7JxUkOWfmXIUnSdJg3mKvqS1V1UFUdBDwIuAl4D3AicF5V7Q+c128DHA7s33+dAJy8EoVLkjSNFnso+zDgK1V1FXAkcFq//zTgqP72kcDp1Tkf2CXJHstSrSRJU26xwfw04O397d2r6rr+9vXA7v3tPYGrJ37mmn7fJpKckGRdknUbNmxYZBmSJE2nBQdzkh2AJwDvmn1fVRVQi3niqjqlqtZW1do1a9Ys5kclSZpaixkxHw58rqq+3m9/feYQdf/9hn7/tcDeEz+3V79PkiTNYzHB/HQ2HsYGOAs4rr99HHDmxP5j+9nZhwI3ThzyliRJd2C7hTwoyV2ARwO/M7H7JOCMJMcDVwFH9/vPBn4dWE83g/tZy1atJElTbkHBXFU/AO4xa9836WZpz35sAc9ZluokSdrK2PlLkqSGGMySJDXEYJYkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhpiMEuS1BCDWZKkhhjMkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIYYzJIkNcRgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDXEYJYkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhpiMEuS1JAFBXOSXZK8O8nlSS5L8tAkuyY5N8mX++937x+bJK9Psj7JxUkOWdmXIEnS9FjoiPl1wIeq6gDggcBlwInAeVW1P3Bevw1wOLB//3UCcPKyVixJ0hSbN5iT7Aw8AjgVoKr+s6q+AxwJnNY/7DTgqP72kcDp1Tkf2CXJHsteuSRJU2ghI+b9gA3Am5NcmOSNSe4C7F5V1/WPuR7Yvb+9J3D1xM9f0++TJEnzWEgwbwccApxcVQcDP2DjYWsAqqqAWswTJzkhybok6zZs2LCYH5UkaWotJJivAa6pqk/32++mC+qvzxyi7r/f0N9/LbD3xM/v1e/bRFWdUlVrq2rtmjVrllq/JElTZd5grqrrgauT/Fy/6zDgi8BZwHH9vuOAM/vbZwHH9rOzDwVunDjkLUmS7sB2C3zc84C3JtkBuAJ4Fl2on5HkeOAq4Oj+sWcDvw6sB27qHytJkhZgQcFcVRcBa+e467A5HlvAc7awLkmStkp2/pIkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhpiMEuS1BCDWZKkhhjMkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIYYzJIkNcRgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDXEYJYkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhpiMEuS1BCDWZKkhhjMkiQ1ZEHBnOTKJJckuSjJun7frknOTfLl/vvd+/1J8vok65NcnOSQlXwBkiRNk8WMmB9ZVQdV1dp++0TgvKraHziv3wY4HNi//zoBOHm5ipUkadptyaHsI4HT+tunAUdN7D+9OucDuyTZYwueR5KkrcZCg7mAc5JckOSEft/uVXVdf/t6YPf+9p7A1RM/e02/T5IkzWO7BT7u4VV1bZJ7AucmuXzyzqqqJLWYJ+4D/gSAffbZZzE/KknS1FrQiLmqru2/3wC8B3gI8PWZQ9T99xv6h18L7D3x43v1+2b/zlOqam1VrV2zZs3SX4EkSVNk3mBOcpckPzVzG3gMcClwFnBc/7DjgDP722cBx/azsw8Fbpw45C1Jku7AQg5l7w68J8nM499WVR9K8lngjCTHA1cBR/ePPxv4dWA9cBPwrGWvWpKkKTVvMFfVFcAD59j/TeCwOfYX8JxlqU6SpK2Mnb8kSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDVkoS05pam274kfWPHnuPKkI1b8OSSNnyNmSZIaYjBLktQQg1mSpIYYzJIkNcRgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDXEYJYkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhpiMEuS1BCDWZKkhhjMkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIasuBgTrJtkguTvL/f3i/Jp5OsT/LOJDv0++/Ub6/v7993ZUqXJGn6LGbE/ALgsontVwGvrar7At8Gju/3Hw98u9//2v5xkiRpARYUzEn2Ao4A3thvB3gU8O7+IacBR/W3j+y36e8/rH+8JEmax0JHzH8JvAT4cb99D+A7VXVrv30NsGd/e0/gaoD+/hv7x0uSpHnMG8xJHgfcUFUXLOcTJzkhybok6zZs2LCcv1qSpNFayIj5YcATklwJvIPuEPbrgF2SbNc/Zi/g2v72tcDeAP39OwPfnP1Lq+qUqlpbVWvXrFmzRS9CkqRpMW8wV9X/rKq9qmpf4GnAv1TVMcBHgCf3DzsOOLO/fVa/TX//v1RVLWvVkiRNqS25jvkPgBclWU93DvnUfv+pwD36/S8CTtyyEiVJ2npsN/9DNqqqjwIf7W9fATxkjsf8CHjKMtQmSdJWx85fkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIYYzJIkNcRgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDXEYJYkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhpiMEuS1BCDWZKkhhjMkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktSQ7YYuQJKklbTviR9Y8ee48qQjlu13OWKWJKkh8wZzkh2TfCbJ55N8IcnL+/37Jfl0kvVJ3plkh37/nfrt9f39+67sS5AkaXosZMR8M/CoqnogcBDw2CSHAq8CXltV9wW+DRzfP/544Nv9/tf2j5MkSQswbzBX5/v95vb9VwGPAt7d7z8NOKq/fWS/TX//YUmybBVLkjTFFnSOOcm2SS4CbgDOBb4CfKeqbu0fcg2wZ397T+BqgP7+G4F7zPE7T0iyLsm6DRs2bNmrkCRpSiwomKvqtqo6CNgLeAhwwJY+cVWdUlVrq2rtmjVrtvTXSZI0FRY1K7uqvgN8BHgosEuSmcut9gKu7W9fC+wN0N+/M/DNZalWkqQpt5BZ2WuS7NLf3gl4NHAZXUA/uX/YccCZ/e2z+m36+/+lqmo5i5YkaVotpMHIHsBpSbalC/Izqur9Sb4IvCPJHwMXAqf2jz8VeEuS9cC3gKetQN2SJE2leYO5qi4GDp5j/xV055tn7/8R8JRlqU6SpK2Mnb8kSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDXEYJYkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhpiMEuS1BCDWZKkhhjMkiQ1xGCWJKkhBrMkSQ0xmCVJaojBLElSQwxmSZIaYjBLktQQg1mSpIYYzJIkNcRgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDXEYJYkqSEGsyRJDZk3mJPsneQjSb6Y5AtJXtDv3zXJuUm+3H+/e78/SV6fZH2Si5McstIvQpKkabGQEfOtwIur6kDgUOA5SQ4ETgTOq6r9gfP6bYDDgf37rxOAk5e9akmSptS8wVxV11XV5/rb3wMuA/YEjgRO6x92GnBUf/tI4PTqnA/skmSPZa9ckqQptKhzzEn2BQ4GPg3sXlXX9XddD+ze394TuHrix67p90mSpHksOJiT3BX4R+CFVfXdyfuqqoBazBMnOSHJuiTrNmzYsJgflSRpai0omJNsTxfKb62qf+p3f33mEHX//YZ+/7XA3hM/vle/bxNVdUpVra2qtWvWrFlq/ZIkTZWFzMoOcCpwWVX9xcRdZwHH9bePA86c2H9sPzv7UODGiUPekiTpDmy3gMc8DPhN4JIkF/X7/hA4CTgjyfHAVcDR/X1nA78OrAduAp61rBVLkjTF5g3mqvpXIJu5+7A5Hl/Ac7awLkmStkp2/pIkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhpiMEuS1BCDWZKkhhjMkiQ1xGCWJKkhBrMkSQ1ZSK/s5ux74gdW/DmuPOmIFX8OSZJmc8QsSVJDDGZJkhpiMEuS1BCDWZKkhhjMkiQ1xGCWJKkho7xcStLcvJRQGj9HzJIkNcRgliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDXEYJYkqSEGsyRJDTGYJUlqiMEsSVJDDGZJkhoybzAneVOSG5JcOrFv1yTnJvly//3u/f4keX2S9UkuTnLIShYvSdK0WciI+e+Bx87adyJwXlXtD5zXbwMcDuzff50AnLw8ZUqStHWYN5ir6uPAt2btPhI4rb99GnDUxP7Tq3M+sEuSPZarWEmSpt1SzzHvXlXX9bevB3bvb+8JXD3xuGv6fZIkaQG229JfUFWVpBb7c0lOoDvczT777LOlZWhA+574gRX9/VeedMSK/n5JaslSR8xfnzlE3X+/od9/LbD3xOP26vfdTlWdUlVrq2rtmjVrlliGJEnTZanBfBZwXH/7OODMif3H9rOzDwVunDjkLUmS5jHvoewkbwd+FdgtyTXAS4GTgDOSHA9cBRzdP/xs4NeB9cBNwLNWoGZJkqbWvMFcVU/fzF2HzfHYAp6zpUVJkrS1svOXJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDXEYJYkqSEGsyRJDdni1aUkSdPL1eNWnyNmSZIaYjBLktQQg1mSpIYYzJIkNcTJXwNa6UkV4MQKSRobR8ySJDXEYJYkqSEGsyRJDTGYJUlqiJO/JDXFSZHa2jliliSpIQazJEkNMZglSWqIwSxJUkMMZkmSGmIwS5LUEINZkqSGGMySJDXEYJYkqSEGsyRJDTGYJUlqiMEsSVJDViSYkzw2yZeSrE9y4ko8hyRJ02jZgznJtsBfA4cDBwJPT3Lgcj+PJEnTaCVGzA8B1lfVFVX1n8A7gCNX4HkkSZo6KxHMewJXT2xf0++TJEnzSFUt7y9Mngw8tqp+u9/+TeAXq+q5sx53AnBCv/lzwJeWtZDb2w34xgo/x0qbhtcAvo6WTMNrgOl4HdPwGsDXsVD3rqo1c92x3Qo82bXA3hPbe/X7NlFVpwCnrMDzzynJuqpau1rPtxKm4TWAr6Ml0/AaYDpexzS8BvB1LIeVOJT9WWD/JPsl2QF4GnDWCjyPJElTZ9lHzFV1a5LnAv8MbAu8qaq+sNzPI0nSNFqJQ9lU1dnA2Svxu7fAqh02X0HT8BrA19GSaXgNMB2vYxpeA/g6ttiyT/6SJElLZ0tOSZIaYjBLktSQFTnHLEnSGCS5W1V9N8muc91fVd9a9Zq2hnPMSe4J7DizXVX/MWA5W50kOwLHA7/Apv8f/utgRS1Ckr+sqhcmeR9wuz+YqnrCAGUtSZJDgTcAPw/sQHflxA+q6m6DFrYVmaZ/T9Mgyfur6nFJvkr3/yMTd1dV3We1a5rqEXOSJwB/DtwLuAG4N3AZXUCMQpInAq8C7kn3DyZ0/1jG9Eb6FuBy4NeAVwDH0P1/GIu39N//bNAqlsdf0fUWeBewFjgW+NlBK1qiJGuAP6BbLGfyA9+jBitqYabp3xMASV4/x+4bgXVVdeZq17MYVfW4/vt+Q9cyY6pHzEk+DzwK+HBVHZzkkcAzq+r4gUtbsCTrgcdX1ZiCbBNJLuz/+19cVQ9Isj3wiao6dOjaFqpfNe30qjpm6Fq2xEw3o5n/F/2+C6vq4KFrW6wk5wDvBP4H8GzgOGBDVf3BoIUtQZK7A3tX1cVD17IUSU4BDqD7wAfwJOCrwD2AK6rqhUPVtlBJDplj943AVVV162rWMtUjZuCWqvpmkm2SbFNVH0nyl0MXtUhfH3Mo927pv38nyf2A6+mOAIxGVd2W5N5JduhXTRurm/qOfBcleTVwHeOdBHqPqjo1yQuq6mPAx5J8duiiFirJR4En0L0PXwDckOSTVfWiQQtbmgcAD6uq2wCSnAx8Ang4cMmQhS3C3wCHABfTHZm8P3ApsHOS/15V56xWIdMezN9Jclfg48Bbk9wA/GDgmhZrXZJ3Au8Fbp7ZWVX/NFxJi3ZKPyL433TtWe8K/J9hS1qSK4BPJjmLiX9HVfUXw5W0aL9Jd175ucDv0fW1f9KgFS3dzAe+65IcAXwNmHMCT6N27icd/Tbd0ZiXJhnliBm4O93f9Y399l2AXfsPtDdv/sea8jXg+JlOlUkOpDv19hLgnwCDeZkcCfyI7g3oGGBnuv/QY3I34CbgMRP7iu4fyihU1Rv7mx8DVn0ixTL6Sv+1DfBTA9eyJFV1VX/zh8DLh6xlGfxxkp2BF9NNaLsb3d/6WGyXZA/gaOCPhi5mC72a7ijMR+lGm48A/iTJXYAPD1nYIvzsZPvoqvpikgOq6ookd/Rzy26qzzFrWEmeWVX/kGSuQ3MFfAs4q6q+vcqlbbWSPA54Jd1EyO0Y52TCqZDkKXRHkT5ZVf89yX2A11TVKI9g9B8yHtJvfraqvjZkPYvVH5n8FvCOftdT6ZZ+/E3gX6vqwatWyzQHc5LvcfvLEW4E1gEvrqorVr+qxRnzpUZJfqeq/i7JSzfzkHsAD2l9Etg0Xd7STyZ8InBJjfSPP8lLqurVSd7A3P8/nj9AWVu9JHuy8QMfAFX18eEqWpwkOwG/S3deHOCTdOedfwTcuaq+v1q1TPuh7L8ErgHeRjcyeBrwM8DngDcBvzpYZQs32kuNqurv+u+bPWSaZAynFqbp8pargUvHGsq9mX//6watYgsl2YvuEPzD+l2fAF5QVdcMV9XSJHkV3QjzC8CP+91FN79nFKrqh/2HvXPoav9SVc3MY1i1UIbpHzF/vqoeOGvfRVV10Fz3tWhKLjUa7ah/tv7aWapqw9C1LEWSB9Mdyv4Ym04mHNMEtk0kuRvd4fjvDV3LYiQ5l27QMPPB75nAMVX16OGqWpokXwIeUFVjmeh1O0l+FTgNuJJuILc3cNwQo/6xXiaxUDclOXrmcqkkR9MdloA5DoE1avalRjszskuN6N54fppu1P8xYC9gbG+iL0vyDeBLwL8n2ZBkjDPL/y/dZMId6SawzXyNTpK1SS6hu7zl0iSfT/KgoetahDVV9eaqurX/+ntgzdBFLdEVwPZDF7GF/hx4TFX9SlU9gu796rVDFDLth7KPAV5Hd56ggPOBZ/bnEp47ZGGLMA2XGt23qp6S5MiqOi3J2+gO241CP3ntYcCDq+qr/b77ACcn+b2qGuSPd4nuVVX3G7qIZfIm4Her6hMASR4OvJnumtox+GaSZwJv77efDnxzwHq2xE10s7LPY9MjMWM63799VX1pZqOq/r0/QrnqpvZQdt+p6VVV9T+GrmVrl+QzVfWQJB+nm1xxPfCZIXrQLkWSC4FHV9U3Zu1fA5wzpq5ZfVORD69ms4SVMlfHsiSfq6q5Ojg1J8m96c4xP5Ru4PAp4Plj7OWf5Li59lfVaatdy1IleRPd+fF/6HcdA2w7xCm3qQ1mgCTnj+lc7Ob0zRNmn58dw6QpAPoGCv9IN5J5M/2ov6r+dtDCFijJpZsbZd7RfS3qr1S4C92o5hZGeLnUROvEY4Gd6EacRTf56Ecj7ZylgSW5E/AcNs7K/gTwN0OcN5/2YD4Z2JOuf+tkp6bRNOdI8rfAnYFHAm8Enkw32hxNv++xu6NR2JhGaNMiyUfu4O6q9hexACDJfsDzgH3Z9BKjMV1+d0ZVHd2f65/r0rWxnFZoyrQH85vn2F1jmg08MRt75vtdgQ9W1S8PXdtCJdmFbnSzL5u+AY3i/FOS25i7lWuAHatqNJNekjxirv1jut50WqRbZOdUul7SM5cY0ff9HoUke1TVdf1h+duZ6DTXrM19qJgxxIeLqZ78VVXPGrqGZfDD/vtNSe5FNzlkjwHrWYqz6SbebfIGNBZVte3QNSyj35+4vSNdp6YL6FZhG5W+HedL6do/Qjfj/xVVdePmf6opP6qquZZLHI2quq6/+QTgLVX1nSHrWaLHDV3AbFMdzFNy/ez7+xHna+gaoxTdIe0x2dHzfm2oqsdPbifZm64Rzxi9iW71n6P77d+km8PwxMEqWpzX9V3xzmHTmcyfG66kJdudbsGdmeZN/zyWJjaTo/okuwMzrTc/U1U3DFHTtB/Kfhdd16xnMNE1q6peMGhhi5DkTjOTD/rJCTvSfdIezYX8SX6PrnPO+9n0DehbgxUlANJ15/9CVR04dC2LNdMsaL59rUryp3QfJr7CRLessZwjn63/t/QY4FnAWuAM4NSq+sqghS1Q3+fiNcBH6U5T/TLw+1X17tWuZapHzIz8+tnev9GtEUofxjf3n0rHNOHoP+n+wf8RG8/lFONeaWqUZvWX3gY4iO5IzBj9MMnDq+pfAZI8jI2nfsbgKcB9atzre/9EVVWS6+kuh7yVbinIdyc5t6peMmx1C/JHdL0KboCfXA75YcBgXmazu2Zdz0i6ZiX5aboZ5TslOZjuExx0S9vdebDClubFdB+SvjHvI7XSJvtL3wq8vao+OVQxW+jZwOn9uebQrQz0W4NWtDiXArsAgxwuXU5JXkA3wfMbdKfafr+qbkmyDfBlujWNW7fNrEPX32Sg7pjTHsxj7pr1a3RvMnsBk32Mvwf84RAFbYH1dJ2BRi3JE4FX0X24CyO8BnhMDR/mU1WfBx7Y98qmqr47cEmLtQtweZLPsukpntFcLjVhV+CJs2dhV9WP0y01OgYfSvLPbOzE9lTgg0MUMtXnmKdBkidV1T8OXceWSPIeugl4H2G87fpmlkx8fFWNYnWvuSTZH/hT4EA2nRA5utMK/ZyLJ3H7y/BG0Xwnya/MtX9kl0vtekf3j2keST+6P4pNG4ycPcR8nqkeMW9ukYGx/OH23p/kGYz0zaf33v5r7L4+5lDuvZnuEqPX0jWteRbjXczmTLr11S9g4gNf65IcUFWXV9XHJid39veNrVPhBWycs5BZ941tHskb+yt2/gmg7xlxNnDYahcy1cHMpk0hdqS7Xm1sb6yjfPOZ1E+82wnYZ7JJ/AitS/JOug8ZkyP/0XSSA3aqqvOSpD/s+LIkFzCeUzyT9qqqxw5dxBK8jY2TN/+NTSdy/g0jmthZVfsNXcMyujbJ31TV7/anQD8A/L8hCpnqYK6qP5/cTvJnwD8PVM5SjfXN5yeSPB74M2AHYL8kB9E1ghjbubS70Z0rf8zEvqL/hD0SN89MyEnyXOBaurkXY/SpJPevqkuGLmSRspnbc203baJv+ZzGdE12Vf3vJK/u2yA/CDhpqNOIUx3Mc7gz3WSqMRnrm8+kl9F1mPooQFVd1C+bOCpT0knuBXR/B88HXkl3OHvOlYFaNdFCcTvgWUmuoDuCMTMZr/X+zLWZ23Ntt+7P7+C+YgQd5fpJnTM+TTdZ+DNAJXniEEfEpjqYZ/VA3ZZuEfIxnZuFbiLCbyX5KuN685l0S1Xd2PUf+InRteYceye5finUp1a3FOr36c4vj9FYZvluzl5JXk/3tzxzm357z+HKWryqeuTQNSyDx8/avhDYvt8/yBGxqQ5mNv0DvpVu8s6tQxWzRIcPXcAy+EI/gW3bflbw8+nWnh2bt9B1kvs1JjrJDVrRAiXZrqpuTfLw+R/dvK/TXcN8X7r+66eO7O96sl/5uln3zd4ehSTHzrW/qk5f7VoWq8UjYVN5udQ0TOFPcreq+u7mXssYXsOMJHem66rzGLpRwYeAV46prShAkgur6uCJlb62Bz5RI1jze2Z5yilZCvWddM2DPkH3wfWqMbXZnUZ9R7kZO9LNZP5cVT15oJIWLMlLqurVs7ri/cQQl3VO64h5Zgr/XBMpxjKF/210I/65XstYXgMAVXUTXTD/EUCSnwP+CvhvQ9a1BKPtJDdhR7qORo9i47+rsU1gO7Cq7g+Q5FS684EaUFU9b3K7X3jnHQOVs1gzR72aOVoxlcE8DVP4q+px/ffRvpYkD6CbjX0vukuM/poukH+RO5400qoxd5K7Z5IX0bWBnOuD3pjMfECiPzw/ZC2a2w+AUbx3VdX7+u8/6YrXX7lw16G6yU1lMM/oVzs5Btivql6ZZB/gp6tqNJ+wk/wG8C8za8z2n0R/tarG0LDj/wEn012reThwEXAacExV/WjIwpaiqmaW2/wYIzpi0duW7oPE5o4ijckDk8y8YYaun/x3GWGL1GmR5H1sujjKgXSrS41Gv8jRs4HbgM8Cd0vyuqp6zarXMo3nmGf059N+DDyqqn6+H+2cU1UPnudHm7GZpe0urKqDh6ppoWbXnuSKMbZ+nNGPOGe7Ebigqi5a7XoWY+Yc89B1aKN+9aL/xu27+my2uEEAAAyLSURBVI1ilv+kWe1Fb6U773/NUPUsxcz7VZJj6Jq8nEj3t73qV8BM9YgZ+MV+wsuFAFX17SQ7DF3UIs3VLnEs/992nLUy1s2T22NqPtBb23+9r99+HHAx8Owk76qqVw9W2fw83tueM+kmsH2YbpQ2WpP9vZPsRjePYWy27yd0HgX8Vb861iAj17G8wS/VLf21mwU/+YQ6tutn1yX5C7rzswDPoZsQNgbXsenKWNdPbI+i+cAsewGHVNX3AZK8lK5t3yPo/p+0HMyr3u9X87pzVf3B0EVsib6390l0S26+ku6Swt2AbZIcW1UfGrK+Rfo74Erg88DHk9wbGOQc87Qfyj6GbumuQ+jObT4Z+F9V9a5BC1uEJHehm2z0X+jC7Fzg/1bVD+7wB7XsklwO3L+qbum37wR8vqoOGMvpBbUjyR8Dn6qqs4euZamSrKNbhnZn4BTg8Ko6P8kBdGt9j+ZvIsluk2vG93OUth3iGvmpHDEn2buqrq6qt/YN+g+jO5R3FPAzw1a3cP1o//1T0l1nGrwV+HSSM/vtxwNv6z88fXG4sjQmSb7Hxpnxf5jkZrqZ5mOcvLZdVZ0DkOQVVXU+QFVdPpbZ8n0v/zfRHWH9MXB0VX2qulHrII1rpnLE3I9sHltVV87a/1+BP6qqMYXzeXQLkN84dC2CJA8Gfqnf/GRVNXPto7TaJicVzp5gOJYJh0kupgvjy5P8IvDqqppzrezVMpUjZuBFwDlJjqiqLwMkOZHu0qlB/4MvwfeBS5Kcy6admla9G40A+BzdikzbASTZp6r+Y9iSNFb9lSL7s2nv9Y8PV9GizVy6NnnZGv32jpv/sabcWlWXA1TVp5P81NAFTWUwV9XZ/eGhDyY5CvhtutWNHlFV3x62ukX7J8bVlel2+kNc/2die1vg9Ko6ZsCyFi3J84CX0vVqvo2NXbPGtKCIGpHkt+lW+9qL7hr/Q+mu+R/NpMiq2nboGpbBTPOdOber6i/m+JkVNZWHsmck+WXgPXQLJhw9xqYWAEl2Avapqi8NXctSJHkz8O9V9af9hKkzgAur6mXDVrY4SdbTXYI3xktB1Jh+9bsHA+f3188eAPxJVT1xnh/VMuqvrtisqnr5atUyYyqDedbkijvRTaz4yQhnTJMr+okJfwbsUFX7JTkIeEVVPWHg0hasn934VrqVgB4JnF1VfzlsVYuX5CPAo0e2kpEaleSzVfXgJBfRfeC7OckXquoXhq5Nw5rWQ9mDnyNYRi+jOwz/UYCquijJKLpnJZmc+PE6uusEP0l3jeAhI2wwcgXw0SQfoFsbGxjmUJemwjV9i933Aucm+TZw1cA1qQFTGcxT5paqunHWpQdjaZIye6GKb9P10P1zxtlg5D/6rx36L2nJquo3+psv64/G7Ey3JKq2clN5KHua9MvanUfXt/VJwPOB7avq2YMWJmlJMgXrxWtlGcyNS3JnunWMH9Pv+mfgj8c2kS3JEcAvsOllIa8YrqLF61u6voTbv46xjfw1oCRf5Q7Wix/zQi9j1k9MfRK3X1Rk1d+nPJTdqCQ70i1Bdl+6SVMPHeukoyR/C9yZbuLXG+lao45m6c0JbwXeSbd4xbOB44ANg1ak0RnzGutT7kz61eKYmEMyBEfMjUryTrrZ5J+gW8v4yqp64bBVLU2Si6vqARPf7wp8sKp+eejaFiPJBVX1oJnX0e/77JiWEVVbpqDByNRIcmlV3W/oOsARc8sOrKr7w0/OM49xhDnjh/33m5Lci25JuD0GrGepbum/X9cfmv8acIfnC6XNmYYGI1PmU0nuX1WXDF2IwdyumRCgqm4dS0P4zXh/f1nIa+haWhbdIe2x+eMkOwMvBt4A3A34vWFL0oi9gI0NRh4502Bk4Jq2Zg8HfqufA3AzG/terHpnPw9lNyrJbWzsjR1gJ+AmRtgkZVI/wWJHF+XQ1s4GI23p11++napa9WvLHTE3akp60P5Ekl9iYrZjEqrq9EGLWqS+scvrgIfSXUv+b8DvVdUVgxamsbLBSENmAjjJPRl4AQ5HzFpxSd5Ctw72RXStUaEb9Y9qhawk5wN/Dby93/U04HlV9YvDVaVpkORX6BuMVNV/Dl3P1ijJE+iaH90LuAG4N3DZEEcwHDFrNaylm8w29k+Bd66qt0xs/0OS3x+sGo1akp8BrqmqmfOZ+9JdVmgwD+OVdBPwPlxVByd5JPDMIQrZZogn1VbnUuCnhy5iqZLs2ndr+mCSE5Psm+TeSV4CnD10fRqtfwRuS3Jf4BRgb+Btw5a0VbulXzlumyTbVNVH6AYVq84Rs1bDbsAXk3yGTRd/GMsKWRewaaem35m4r4D/ueoVaRr8uL/i4jeAN1TVG5JcOHRRW7Hv9D0WPg68NckNbJyAu6oMZq2Glw1dwJawU5NWyC1Jnk7XQe7x/b7tB6xna3ck8CO6SyCPoTvnv+prMYOTvzSAJA8Hnl5Vzxm6lsVIsi1wBLfvpeuyj1q0JAfStXb9t6p6e5L9gKOr6lUDl7ZVSnJ8VZ06a99JVXXiatfiiFmrIsnBwDOApwBfpTu/Njbvo/tEfQnjWXpTjaqqL9KtFjez/VXAUB7Ok5L8qKreCpDkr+j6R6w6g1krJsnPAk/vv75BtwBEquqRgxa2dHsN0QVI0ynJ/sCf0q1RPtkr29WlhvEk4KwkPwYeC3ynqo4fohBnZWslXU7X9/dxVfXwqnoDG69jHqMPJnnM/A+TFuTNwMnArXQrr50O/MOgFW2FJq662An4bbqlXb8HvHy+tbNXrCbPMWulJDmKrgnHw4APAe8A3jjWyVT97Nl/oPtAewsjb4+qYU2sVnbJxII1F1TVg4aubWsya33s2etkD7I+toeytWKq6r3Ae5PchW7G4wuBeyY5GXhPVZ0zaIGL9xd07TgvmYJmKRrezUm2Ab6c5LnAtcBdB65pq9PiQMERs1ZVv/7sU4CnVtVhQ9ezGEk+DvxqVTnxS1ssyYOBy4Bd6LpO7Qy8uqrOH7SwrVSSY+faP0RPf4NZWqAkfw/cB/ggmzZK8XIpaeSSvGFic0fgMOBzVfXk1a7FQ9nSwn21/9qh/5IWLclZd3T/iDriTZWqet7kdr/y1zuGqMURs7RISe5cVTcNXYfGKckG4Gq6Vco+zaaTjaiqjw1RlzaVZHvg0qr6udV+bkfM0gIleShwKt0EnX2SPBD4nar63WEr08j8NPBouuv7nwF8AHh7VX1h0Kq2ckneRzcrG7orLw4EzhikFkfM0sIk+TTwZOCsqjq433dpVd1v2Mo0VknuRBfQrwFeXlV/NXBJW61+TewZtwJXVdU1Q9TiiFlahKq6OtnkyOOYG6ZoIH0gH0EXyvsCrwfeM2RNW7vJUwhJdgO+OVQtBrO0cFcn+SWg+vNPL6C73EVasCSnA/ejW8v75VV16cAlbdWSHAqcBHyL7rK1t9AtVbtNkmOr6kOrXpOHsqWF6T9Fvw74L3QTds4BXtAvri4tSN+LeWad38k3YDvJDSDJOuAP6a4jPwU4vKrOT3IA3bn/g1e9JoNZkrS1SnJRVR3U376sqn5+4r4LhwhmD2VLC5Tk9XPsvhFYV1VnrnY9kpbFZCe/H866b5CRqyNmaYGSnAIcALyr3/UkuoYj9wCuqKoXDlWbpKVJchvdqYXQrTA106MgwI5Vtf2q12QwSwuT5HzgYVV1W7+9HfAJ4OF0C1scOGR9kqaD6zFLC3d3Nl395y7Arn1Q3zz3j0jS4niOWVq4VwMXJfko3WGuRwB/0i9r+eEhC5M0PTyULS1Ckj2Ah/Sbn62qrw1Zj6TpYzBLi5BkT+DeTBxtqqqPD1eRpGnjoWxpgZK8Cngq8AU2XmJRgMEsadk4YpYWKMmXgAdUlRO9JK0YZ2VLC3cFsOrXNEraungoW1q4m+hmZZ/HxOVRVfX84UqSNG0MZmnhzuq/JGnFeI5ZWoQkOwH7VNWXhq5F0nTyHLO0QEkeD1wEfKjfPiiJI2hJy8pglhbuZXTNRb4DUFUXAfcZsiBJ08dglhbulqq6cda+H8/5SElaIid/SQv3hSTPALZNsj/wfOBTA9ckaco4YpYW7nnAL9BdKvU24EbANZglLStHzNI8kuwIPBu4L3AJ8NCqunXYqiRNKy+XkuaR5J3ALcAngMOBK6vKkbKkFWEwS/NIcklV3b+/vR3wmao6ZOCyJE0pzzFL87tl5oaHsCWtNEfM0jyS3Ab8YGYT2Imub3aAqqq7DVWbpOljMEuS1BAPZUuS1BCDWZKkhhjMkiQ1xGCWJKkhBrMkSQ0xmCVJasj/B4rKJT8FpF41AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aazE0FP86HJX"
      },
      "source": [
        "def preprocess_text(sen):\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GooZcnOz6PCQ"
      },
      "source": [
        "X = []\n",
        "kalimat = list(curhat[\"Curhat\"])\n",
        "for isi in kalimat:\n",
        "    X.append(preprocess_text(isi))\n",
        "\n",
        "y = curhat[[\"Keluarga\", \"Percintaan\", \"Anak Remaja\", \"Pengembangan Diri\", \"Trauma\", \"Phobia\", \"Masalah Emosi\", \"Bullying\", \"Bukan Psikologi\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ad3B6CW6qkO",
        "outputId": "41717a9e-ce00-4600-930e-6c5c563726d5"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.80, test_size = 0.20, random_state = 42)\n",
        "print(len(X_train))\n",
        "print(len(y_train))\n",
        "print(len(X_test))\n",
        "print(len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1073\n",
            "1073\n",
            "269\n",
            "269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0TyBUk_602v"
      },
      "source": [
        "y1_train = y_train[[\"Keluarga\"]].values\n",
        "y1_test =  y_test[[\"Keluarga\"]].values\n",
        "\n",
        "y2_train = y_train[[\"Percintaan\"]].values\n",
        "y2_test =  y_test[[\"Percintaan\"]].values\n",
        "\n",
        "y3_train = y_train[[\"Anak Remaja\"]].values\n",
        "y3_test =  y_test[[\"Anak Remaja\"]].values\n",
        "\n",
        "y4_train = y_train[[\"Pengembangan Diri\"]].values\n",
        "y4_test =  y_test[[\"Pengembangan Diri\"]].values\n",
        "\n",
        "y5_train = y_train[[\"Trauma\"]].values\n",
        "y5_test =  y_test[[\"Trauma\"]].values\n",
        "\n",
        "y6_train = y_train[[\"Phobia\"]].values\n",
        "y6_test =  y_test[[\"Phobia\"]].values\n",
        "\n",
        "y7_train = y_train[[\"Masalah Emosi\"]].values\n",
        "y7_test =  y_test[[\"Masalah Emosi\"]].values\n",
        "\n",
        "y8_train = y_train[[\"Bullying\"]].values\n",
        "y8_test =  y_test[[\"Bullying\"]].values\n",
        "\n",
        "y9_train = y_train[[\"Bukan Psikologi\"]].values\n",
        "y9_test =  y_test[[\"Bukan Psikologi\"]].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1B2Rbov7BeK"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 200\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBQTVxhP7FhE"
      },
      "source": [
        "embeddings_dictionary = dict()\n",
        "\n",
        "glove_file = open('/content/drive/MyDrive/E-RCV/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary[word] = vector_dimensions\n",
        "glove_file.close()\n",
        "\n",
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcwG4TTX7SQD"
      },
      "source": [
        "input_1 = Input(shape=(maxlen,))\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(input_1)\n",
        "LSTM_Layer1 = LSTM(128)(embedding_layer)\n",
        "\n",
        "output1 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
        "output2 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
        "output3 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
        "output4 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
        "output5 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
        "output6 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
        "output7 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
        "output8 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
        "output9 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
        "\n",
        "model = Model(inputs=input_1, outputs=[output1, output2, output3, output4, output5, output6, output7, output8, output9])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnYKJ_ET7Zb0",
        "outputId": "05f09d4a-0f35-4f1d-f0f9-f67c9baf3372"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 200, 100)     697100      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          117248      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            129         lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            129         lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            129         lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            129         lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            129         lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            129         lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            129         lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1)            129         lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1)            129         lstm[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 815,509\n",
            "Trainable params: 118,409\n",
            "Non-trainable params: 697,100\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0OlhVZ-7gYW",
        "outputId": "2ab6c362-b576-4a06-8fa7-d98e75518df9"
      },
      "source": [
        "history = model.fit(x=X_train, y=[y1_train, \n",
        "                                  y2_train, \n",
        "                                  y3_train,\n",
        "                                  y4_train,\n",
        "                                  y5_train,\n",
        "                                  y6_train,\n",
        "                                  y7_train,\n",
        "                                  y8_train,\n",
        "                                  y9_train], \n",
        "                    batch_size=8192, epochs=100, verbose=1, validation_split=0.20, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 23s 23s/step - loss: 6.2381 - dense_loss: 0.6933 - dense_1_loss: 0.6929 - dense_2_loss: 0.6928 - dense_3_loss: 0.6930 - dense_4_loss: 0.6930 - dense_5_loss: 0.6934 - dense_6_loss: 0.6932 - dense_7_loss: 0.6931 - dense_8_loss: 0.6933 - dense_acc: 0.8671 - dense_1_acc: 0.9452 - dense_2_acc: 0.9114 - dense_3_acc: 0.6550 - dense_4_acc: 0.8916 - dense_5_acc: 0.9429 - dense_6_acc: 0.4382 - dense_7_acc: 0.9510 - dense_8_acc: 0.7611 - val_loss: 6.2193 - val_dense_loss: 0.6921 - val_dense_1_loss: 0.6896 - val_dense_2_loss: 0.6902 - val_dense_3_loss: 0.6930 - val_dense_4_loss: 0.6901 - val_dense_5_loss: 0.6903 - val_dense_6_loss: 0.6927 - val_dense_7_loss: 0.6896 - val_dense_8_loss: 0.6916 - val_dense_acc: 0.8558 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6465 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9628 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 6.2180 - dense_loss: 0.6919 - dense_1_loss: 0.6893 - dense_2_loss: 0.6902 - dense_3_loss: 0.6925 - dense_4_loss: 0.6902 - dense_5_loss: 0.6901 - dense_6_loss: 0.6931 - dense_7_loss: 0.6894 - dense_8_loss: 0.6913 - dense_acc: 0.8765 - dense_1_acc: 0.9569 - dense_2_acc: 0.9172 - dense_3_acc: 0.6585 - dense_4_acc: 0.8904 - dense_5_acc: 0.9627 - dense_6_acc: 0.5676 - dense_7_acc: 0.9522 - dense_8_acc: 0.7751 - val_loss: 6.1968 - val_dense_loss: 0.6905 - val_dense_1_loss: 0.6854 - val_dense_2_loss: 0.6870 - val_dense_3_loss: 0.6928 - val_dense_4_loss: 0.6867 - val_dense_5_loss: 0.6866 - val_dense_6_loss: 0.6926 - val_dense_7_loss: 0.6857 - val_dense_8_loss: 0.6897 - val_dense_acc: 0.8558 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9628 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 6.1943 - dense_loss: 0.6902 - dense_1_loss: 0.6850 - dense_2_loss: 0.6870 - dense_3_loss: 0.6920 - dense_4_loss: 0.6868 - dense_5_loss: 0.6862 - dense_6_loss: 0.6928 - dense_7_loss: 0.6851 - dense_8_loss: 0.6891 - dense_acc: 0.8776 - dense_1_acc: 0.9569 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8904 - dense_5_acc: 0.9650 - dense_6_acc: 0.5676 - dense_7_acc: 0.9534 - dense_8_acc: 0.7774 - val_loss: 6.1680 - val_dense_loss: 0.6884 - val_dense_1_loss: 0.6799 - val_dense_2_loss: 0.6828 - val_dense_3_loss: 0.6924 - val_dense_4_loss: 0.6824 - val_dense_5_loss: 0.6819 - val_dense_6_loss: 0.6924 - val_dense_7_loss: 0.6805 - val_dense_8_loss: 0.6872 - val_dense_acc: 0.8558 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 6.1640 - dense_loss: 0.6880 - dense_1_loss: 0.6795 - dense_2_loss: 0.6829 - dense_3_loss: 0.6913 - dense_4_loss: 0.6825 - dense_5_loss: 0.6813 - dense_6_loss: 0.6926 - dense_7_loss: 0.6796 - dense_8_loss: 0.6863 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5664 - dense_7_acc: 0.9534 - dense_8_acc: 0.7774 - val_loss: 6.1291 - val_dense_loss: 0.6857 - val_dense_1_loss: 0.6726 - val_dense_2_loss: 0.6771 - val_dense_3_loss: 0.6918 - val_dense_4_loss: 0.6767 - val_dense_5_loss: 0.6756 - val_dense_6_loss: 0.6921 - val_dense_7_loss: 0.6735 - val_dense_8_loss: 0.6840 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 6.1235 - dense_loss: 0.6851 - dense_1_loss: 0.6721 - dense_2_loss: 0.6773 - dense_3_loss: 0.6903 - dense_4_loss: 0.6767 - dense_5_loss: 0.6749 - dense_6_loss: 0.6923 - dense_7_loss: 0.6721 - dense_8_loss: 0.6826 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5664 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 6.0738 - val_dense_loss: 0.6817 - val_dense_1_loss: 0.6622 - val_dense_2_loss: 0.6689 - val_dense_3_loss: 0.6911 - val_dense_4_loss: 0.6685 - val_dense_5_loss: 0.6667 - val_dense_6_loss: 0.6918 - val_dense_7_loss: 0.6635 - val_dense_8_loss: 0.6794 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 6.0660 - dense_loss: 0.6809 - dense_1_loss: 0.6615 - dense_2_loss: 0.6692 - dense_3_loss: 0.6890 - dense_4_loss: 0.6686 - dense_5_loss: 0.6658 - dense_6_loss: 0.6919 - dense_7_loss: 0.6616 - dense_8_loss: 0.6775 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5664 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 5.9885 - val_dense_loss: 0.6755 - val_dense_1_loss: 0.6461 - val_dense_2_loss: 0.6561 - val_dense_3_loss: 0.6901 - val_dense_4_loss: 0.6559 - val_dense_5_loss: 0.6530 - val_dense_6_loss: 0.6913 - val_dense_7_loss: 0.6482 - val_dense_8_loss: 0.6723 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 5.9779 - dense_loss: 0.6745 - dense_1_loss: 0.6454 - dense_2_loss: 0.6566 - dense_3_loss: 0.6869 - dense_4_loss: 0.6563 - dense_5_loss: 0.6519 - dense_6_loss: 0.6912 - dense_7_loss: 0.6455 - dense_8_loss: 0.6696 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5664 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 5.8390 - val_dense_loss: 0.6643 - val_dense_1_loss: 0.6180 - val_dense_2_loss: 0.6332 - val_dense_3_loss: 0.6890 - val_dense_4_loss: 0.6341 - val_dense_5_loss: 0.6288 - val_dense_6_loss: 0.6905 - val_dense_7_loss: 0.6213 - val_dense_8_loss: 0.6598 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 5.8243 - dense_loss: 0.6631 - dense_1_loss: 0.6176 - dense_2_loss: 0.6344 - dense_3_loss: 0.6831 - dense_4_loss: 0.6352 - dense_5_loss: 0.6275 - dense_6_loss: 0.6901 - dense_7_loss: 0.6176 - dense_8_loss: 0.6557 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5664 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 5.4888 - val_dense_loss: 0.6371 - val_dense_1_loss: 0.5514 - val_dense_2_loss: 0.5791 - val_dense_3_loss: 0.6886 - val_dense_4_loss: 0.5833 - val_dense_5_loss: 0.5708 - val_dense_6_loss: 0.6886 - val_dense_7_loss: 0.5590 - val_dense_8_loss: 0.6309 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 5.4650 - dense_loss: 0.6360 - dense_1_loss: 0.5525 - dense_2_loss: 0.5827 - dense_3_loss: 0.6741 - dense_4_loss: 0.5865 - dense_5_loss: 0.5699 - dense_6_loss: 0.6877 - dense_7_loss: 0.5522 - dense_8_loss: 0.6234 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5676 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 4.2269 - val_dense_loss: 0.5210 - val_dense_1_loss: 0.3050 - val_dense_2_loss: 0.3792 - val_dense_3_loss: 0.6768 - val_dense_4_loss: 0.4068 - val_dense_5_loss: 0.3484 - val_dense_6_loss: 0.6870 - val_dense_7_loss: 0.3435 - val_dense_8_loss: 0.5591 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 4.1541 - dense_loss: 0.5130 - dense_1_loss: 0.3131 - dense_2_loss: 0.3919 - dense_3_loss: 0.6439 - dense_4_loss: 0.4105 - dense_5_loss: 0.3488 - dense_6_loss: 0.6833 - dense_7_loss: 0.3159 - dense_8_loss: 0.5337 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5676 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.7351 - val_dense_loss: 0.4376 - val_dense_1_loss: 0.1909 - val_dense_2_loss: 0.2810 - val_dense_3_loss: 0.7130 - val_dense_4_loss: 0.3418 - val_dense_5_loss: 0.2242 - val_dense_6_loss: 0.6958 - val_dense_7_loss: 0.2610 - val_dense_8_loss: 0.5900 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.6000 - dense_loss: 0.4181 - dense_1_loss: 0.2021 - dense_2_loss: 0.3019 - dense_3_loss: 0.6590 - dense_4_loss: 0.3454 - dense_5_loss: 0.2259 - dense_6_loss: 0.6890 - dense_7_loss: 0.2122 - dense_8_loss: 0.5464 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5676 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.7151 - val_dense_loss: 0.4099 - val_dense_1_loss: 0.1652 - val_dense_2_loss: 0.2571 - val_dense_3_loss: 0.7635 - val_dense_4_loss: 0.3458 - val_dense_5_loss: 0.1797 - val_dense_6_loss: 0.7043 - val_dense_7_loss: 0.2532 - val_dense_8_loss: 0.6363 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.5423 - dense_loss: 0.3826 - dense_1_loss: 0.1783 - dense_2_loss: 0.2838 - dense_3_loss: 0.6947 - dense_4_loss: 0.3499 - dense_5_loss: 0.1823 - dense_6_loss: 0.6960 - dense_7_loss: 0.1916 - dense_8_loss: 0.5831 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5676 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.7532 - val_dense_loss: 0.4040 - val_dense_1_loss: 0.1594 - val_dense_2_loss: 0.2530 - val_dense_3_loss: 0.7915 - val_dense_4_loss: 0.3589 - val_dense_5_loss: 0.1598 - val_dense_6_loss: 0.7057 - val_dense_7_loss: 0.2588 - val_dense_8_loss: 0.6620 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.5609 - dense_loss: 0.3711 - dense_1_loss: 0.1741 - dense_2_loss: 0.2834 - dense_3_loss: 0.7159 - dense_4_loss: 0.3633 - dense_5_loss: 0.1628 - dense_6_loss: 0.6972 - dense_7_loss: 0.1887 - dense_8_loss: 0.6043 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5676 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.7601 - val_dense_loss: 0.4063 - val_dense_1_loss: 0.1590 - val_dense_2_loss: 0.2541 - val_dense_3_loss: 0.7895 - val_dense_4_loss: 0.3674 - val_dense_5_loss: 0.1507 - val_dense_6_loss: 0.7016 - val_dense_7_loss: 0.2654 - val_dense_8_loss: 0.6662 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.5628 - dense_loss: 0.3695 - dense_1_loss: 0.1748 - dense_2_loss: 0.2869 - dense_3_loss: 0.7145 - dense_4_loss: 0.3718 - dense_5_loss: 0.1541 - dense_6_loss: 0.6936 - dense_7_loss: 0.1899 - dense_8_loss: 0.6078 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5676 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.7323 - val_dense_loss: 0.4105 - val_dense_1_loss: 0.1597 - val_dense_2_loss: 0.2558 - val_dense_3_loss: 0.7678 - val_dense_4_loss: 0.3702 - val_dense_5_loss: 0.1465 - val_dense_6_loss: 0.6956 - val_dense_7_loss: 0.2699 - val_dense_8_loss: 0.6562 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.5395 - dense_loss: 0.3710 - dense_1_loss: 0.1763 - dense_2_loss: 0.2899 - dense_3_loss: 0.6980 - dense_4_loss: 0.3747 - dense_5_loss: 0.1502 - dense_6_loss: 0.6887 - dense_7_loss: 0.1914 - dense_8_loss: 0.5994 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5676 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.6840 - val_dense_loss: 0.4141 - val_dense_1_loss: 0.1605 - val_dense_2_loss: 0.2569 - val_dense_3_loss: 0.7378 - val_dense_4_loss: 0.3690 - val_dense_5_loss: 0.1446 - val_dense_6_loss: 0.6906 - val_dense_7_loss: 0.2722 - val_dense_8_loss: 0.6382 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.5018 - dense_loss: 0.3729 - dense_1_loss: 0.1774 - dense_2_loss: 0.2916 - dense_3_loss: 0.6764 - dense_4_loss: 0.3734 - dense_5_loss: 0.1485 - dense_6_loss: 0.6849 - dense_7_loss: 0.1923 - dense_8_loss: 0.5844 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5676 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.6295 - val_dense_loss: 0.4162 - val_dense_1_loss: 0.1609 - val_dense_2_loss: 0.2571 - val_dense_3_loss: 0.7086 - val_dense_4_loss: 0.3652 - val_dense_5_loss: 0.1438 - val_dense_6_loss: 0.6880 - val_dense_7_loss: 0.2726 - val_dense_8_loss: 0.6170 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.4615 - dense_loss: 0.3741 - dense_1_loss: 0.1781 - dense_2_loss: 0.2919 - dense_3_loss: 0.6570 - dense_4_loss: 0.3694 - dense_5_loss: 0.1478 - dense_6_loss: 0.6836 - dense_7_loss: 0.1924 - dense_8_loss: 0.5671 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5676 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5801 - val_dense_loss: 0.4167 - val_dense_1_loss: 0.1610 - val_dense_2_loss: 0.2566 - val_dense_3_loss: 0.6862 - val_dense_4_loss: 0.3600 - val_dense_5_loss: 0.1435 - val_dense_6_loss: 0.6878 - val_dense_7_loss: 0.2717 - val_dense_8_loss: 0.5964 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5535 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.4279 - dense_loss: 0.3744 - dense_1_loss: 0.1782 - dense_2_loss: 0.2911 - dense_3_loss: 0.6448 - dense_4_loss: 0.3641 - dense_5_loss: 0.1477 - dense_6_loss: 0.6846 - dense_7_loss: 0.1920 - dense_8_loss: 0.5509 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5676 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5421 - val_dense_loss: 0.4159 - val_dense_1_loss: 0.1609 - val_dense_2_loss: 0.2558 - val_dense_3_loss: 0.6733 - val_dense_4_loss: 0.3544 - val_dense_5_loss: 0.1435 - val_dense_6_loss: 0.6892 - val_dense_7_loss: 0.2700 - val_dense_8_loss: 0.5791 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.4058 - dense_loss: 0.3738 - dense_1_loss: 0.1780 - dense_2_loss: 0.2896 - dense_3_loss: 0.6418 - dense_4_loss: 0.3583 - dense_5_loss: 0.1478 - dense_6_loss: 0.6868 - dense_7_loss: 0.1914 - dense_8_loss: 0.5382 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5176 - val_dense_loss: 0.4143 - val_dense_1_loss: 0.1606 - val_dense_2_loss: 0.2548 - val_dense_3_loss: 0.6695 - val_dense_4_loss: 0.3492 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6906 - val_dense_7_loss: 0.2680 - val_dense_8_loss: 0.5669 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3957 - dense_loss: 0.3728 - dense_1_loss: 0.1776 - dense_2_loss: 0.2879 - dense_3_loss: 0.6466 - dense_4_loss: 0.3529 - dense_5_loss: 0.1479 - dense_6_loss: 0.6888 - dense_7_loss: 0.1906 - dense_8_loss: 0.5306 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5046 - val_dense_loss: 0.4123 - val_dense_1_loss: 0.1602 - val_dense_2_loss: 0.2540 - val_dense_3_loss: 0.6716 - val_dense_4_loss: 0.3449 - val_dense_5_loss: 0.1437 - val_dense_6_loss: 0.6913 - val_dense_7_loss: 0.2661 - val_dense_8_loss: 0.5605 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3947 - dense_loss: 0.3716 - dense_1_loss: 0.1770 - dense_2_loss: 0.2862 - dense_3_loss: 0.6555 - dense_4_loss: 0.3484 - dense_5_loss: 0.1481 - dense_6_loss: 0.6896 - dense_7_loss: 0.1899 - dense_8_loss: 0.5284 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4992 - val_dense_loss: 0.4103 - val_dense_1_loss: 0.1599 - val_dense_2_loss: 0.2534 - val_dense_3_loss: 0.6755 - val_dense_4_loss: 0.3419 - val_dense_5_loss: 0.1439 - val_dense_6_loss: 0.6910 - val_dense_7_loss: 0.2643 - val_dense_8_loss: 0.5590 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3980 - dense_loss: 0.3706 - dense_1_loss: 0.1765 - dense_2_loss: 0.2847 - dense_3_loss: 0.6638 - dense_4_loss: 0.3452 - dense_5_loss: 0.1483 - dense_6_loss: 0.6890 - dense_7_loss: 0.1894 - dense_8_loss: 0.5306 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4975 - val_dense_loss: 0.4085 - val_dense_1_loss: 0.1596 - val_dense_2_loss: 0.2531 - val_dense_3_loss: 0.6780 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.1440 - val_dense_6_loss: 0.6901 - val_dense_7_loss: 0.2628 - val_dense_8_loss: 0.5610 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.4016 - dense_loss: 0.3697 - dense_1_loss: 0.1760 - dense_2_loss: 0.2836 - dense_3_loss: 0.6684 - dense_4_loss: 0.3434 - dense_5_loss: 0.1485 - dense_6_loss: 0.6875 - dense_7_loss: 0.1890 - dense_8_loss: 0.5354 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4968 - val_dense_loss: 0.4071 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2531 - val_dense_3_loss: 0.6780 - val_dense_4_loss: 0.3402 - val_dense_5_loss: 0.1442 - val_dense_6_loss: 0.6890 - val_dense_7_loss: 0.2616 - val_dense_8_loss: 0.5643 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.4031 - dense_loss: 0.3692 - dense_1_loss: 0.1755 - dense_2_loss: 0.2828 - dense_3_loss: 0.6684 - dense_4_loss: 0.3431 - dense_5_loss: 0.1487 - dense_6_loss: 0.6858 - dense_7_loss: 0.1887 - dense_8_loss: 0.5409 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4962 - val_dense_loss: 0.4060 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2533 - val_dense_3_loss: 0.6758 - val_dense_4_loss: 0.3412 - val_dense_5_loss: 0.1443 - val_dense_6_loss: 0.6884 - val_dense_7_loss: 0.2606 - val_dense_8_loss: 0.5674 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.4017 - dense_loss: 0.3689 - dense_1_loss: 0.1751 - dense_2_loss: 0.2822 - dense_3_loss: 0.6643 - dense_4_loss: 0.3439 - dense_5_loss: 0.1488 - dense_6_loss: 0.6843 - dense_7_loss: 0.1886 - dense_8_loss: 0.5454 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4956 - val_dense_loss: 0.4053 - val_dense_1_loss: 0.1590 - val_dense_2_loss: 0.2537 - val_dense_3_loss: 0.6728 - val_dense_4_loss: 0.3429 - val_dense_5_loss: 0.1444 - val_dense_6_loss: 0.6883 - val_dense_7_loss: 0.2599 - val_dense_8_loss: 0.5692 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3980 - dense_loss: 0.3689 - dense_1_loss: 0.1748 - dense_2_loss: 0.2820 - dense_3_loss: 0.6581 - dense_4_loss: 0.3455 - dense_5_loss: 0.1490 - dense_6_loss: 0.6835 - dense_7_loss: 0.1884 - dense_8_loss: 0.5478 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4955 - val_dense_loss: 0.4048 - val_dense_1_loss: 0.1590 - val_dense_2_loss: 0.2542 - val_dense_3_loss: 0.6703 - val_dense_4_loss: 0.3449 - val_dense_5_loss: 0.1445 - val_dense_6_loss: 0.6890 - val_dense_7_loss: 0.2593 - val_dense_8_loss: 0.5694 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3931 - dense_loss: 0.3690 - dense_1_loss: 0.1746 - dense_2_loss: 0.2819 - dense_3_loss: 0.6515 - dense_4_loss: 0.3474 - dense_5_loss: 0.1491 - dense_6_loss: 0.6833 - dense_7_loss: 0.1884 - dense_8_loss: 0.5479 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4963 - val_dense_loss: 0.4045 - val_dense_1_loss: 0.1590 - val_dense_2_loss: 0.2548 - val_dense_3_loss: 0.6696 - val_dense_4_loss: 0.3468 - val_dense_5_loss: 0.1446 - val_dense_6_loss: 0.6901 - val_dense_7_loss: 0.2589 - val_dense_8_loss: 0.5680 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3879 - dense_loss: 0.3692 - dense_1_loss: 0.1744 - dense_2_loss: 0.2820 - dense_3_loss: 0.6461 - dense_4_loss: 0.3492 - dense_5_loss: 0.1492 - dense_6_loss: 0.6837 - dense_7_loss: 0.1884 - dense_8_loss: 0.5459 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4982 - val_dense_loss: 0.4044 - val_dense_1_loss: 0.1590 - val_dense_2_loss: 0.2554 - val_dense_3_loss: 0.6710 - val_dense_4_loss: 0.3481 - val_dense_5_loss: 0.1447 - val_dense_6_loss: 0.6913 - val_dense_7_loss: 0.2586 - val_dense_8_loss: 0.5658 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3831 - dense_loss: 0.3693 - dense_1_loss: 0.1742 - dense_2_loss: 0.2821 - dense_3_loss: 0.6427 - dense_4_loss: 0.3505 - dense_5_loss: 0.1492 - dense_6_loss: 0.6843 - dense_7_loss: 0.1883 - dense_8_loss: 0.5425 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5010 - val_dense_loss: 0.4044 - val_dense_1_loss: 0.1590 - val_dense_2_loss: 0.2559 - val_dense_3_loss: 0.6744 - val_dense_4_loss: 0.3487 - val_dense_5_loss: 0.1447 - val_dense_6_loss: 0.6923 - val_dense_7_loss: 0.2584 - val_dense_8_loss: 0.5632 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3791 - dense_loss: 0.3693 - dense_1_loss: 0.1742 - dense_2_loss: 0.2823 - dense_3_loss: 0.6414 - dense_4_loss: 0.3510 - dense_5_loss: 0.1492 - dense_6_loss: 0.6849 - dense_7_loss: 0.1883 - dense_8_loss: 0.5385 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5042 - val_dense_loss: 0.4044 - val_dense_1_loss: 0.1591 - val_dense_2_loss: 0.2563 - val_dense_3_loss: 0.6791 - val_dense_4_loss: 0.3484 - val_dense_5_loss: 0.1447 - val_dense_6_loss: 0.6929 - val_dense_7_loss: 0.2582 - val_dense_8_loss: 0.5611 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3758 - dense_loss: 0.3693 - dense_1_loss: 0.1741 - dense_2_loss: 0.2824 - dense_3_loss: 0.6420 - dense_4_loss: 0.3507 - dense_5_loss: 0.1492 - dense_6_loss: 0.6852 - dense_7_loss: 0.1883 - dense_8_loss: 0.5346 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5074 - val_dense_loss: 0.4045 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2566 - val_dense_3_loss: 0.6842 - val_dense_4_loss: 0.3475 - val_dense_5_loss: 0.1446 - val_dense_6_loss: 0.6929 - val_dense_7_loss: 0.2581 - val_dense_8_loss: 0.5598 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3731 - dense_loss: 0.3691 - dense_1_loss: 0.1741 - dense_2_loss: 0.2825 - dense_3_loss: 0.6436 - dense_4_loss: 0.3498 - dense_5_loss: 0.1492 - dense_6_loss: 0.6851 - dense_7_loss: 0.1883 - dense_8_loss: 0.5314 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5101 - val_dense_loss: 0.4046 - val_dense_1_loss: 0.1594 - val_dense_2_loss: 0.2567 - val_dense_3_loss: 0.6887 - val_dense_4_loss: 0.3461 - val_dense_5_loss: 0.1445 - val_dense_6_loss: 0.6924 - val_dense_7_loss: 0.2580 - val_dense_8_loss: 0.5597 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3708 - dense_loss: 0.3690 - dense_1_loss: 0.1741 - dense_2_loss: 0.2825 - dense_3_loss: 0.6455 - dense_4_loss: 0.3485 - dense_5_loss: 0.1491 - dense_6_loss: 0.6847 - dense_7_loss: 0.1883 - dense_8_loss: 0.5292 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5120 - val_dense_loss: 0.4048 - val_dense_1_loss: 0.1595 - val_dense_2_loss: 0.2567 - val_dense_3_loss: 0.6919 - val_dense_4_loss: 0.3445 - val_dense_5_loss: 0.1444 - val_dense_6_loss: 0.6917 - val_dense_7_loss: 0.2579 - val_dense_8_loss: 0.5606 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3689 - dense_loss: 0.3688 - dense_1_loss: 0.1742 - dense_2_loss: 0.2825 - dense_3_loss: 0.6470 - dense_4_loss: 0.3469 - dense_5_loss: 0.1489 - dense_6_loss: 0.6841 - dense_7_loss: 0.1883 - dense_8_loss: 0.5282 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5130 - val_dense_loss: 0.4050 - val_dense_1_loss: 0.1597 - val_dense_2_loss: 0.2566 - val_dense_3_loss: 0.6933 - val_dense_4_loss: 0.3430 - val_dense_5_loss: 0.1443 - val_dense_6_loss: 0.6909 - val_dense_7_loss: 0.2578 - val_dense_8_loss: 0.5623 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3672 - dense_loss: 0.3686 - dense_1_loss: 0.1742 - dense_2_loss: 0.2824 - dense_3_loss: 0.6477 - dense_4_loss: 0.3455 - dense_5_loss: 0.1487 - dense_6_loss: 0.6836 - dense_7_loss: 0.1883 - dense_8_loss: 0.5281 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5129 - val_dense_loss: 0.4054 - val_dense_1_loss: 0.1598 - val_dense_2_loss: 0.2564 - val_dense_3_loss: 0.6930 - val_dense_4_loss: 0.3418 - val_dense_5_loss: 0.1441 - val_dense_6_loss: 0.6902 - val_dense_7_loss: 0.2577 - val_dense_8_loss: 0.5646 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3656 - dense_loss: 0.3685 - dense_1_loss: 0.1742 - dense_2_loss: 0.2823 - dense_3_loss: 0.6475 - dense_4_loss: 0.3443 - dense_5_loss: 0.1486 - dense_6_loss: 0.6832 - dense_7_loss: 0.1883 - dense_8_loss: 0.5288 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5119 - val_dense_loss: 0.4057 - val_dense_1_loss: 0.1599 - val_dense_2_loss: 0.2562 - val_dense_3_loss: 0.6911 - val_dense_4_loss: 0.3409 - val_dense_5_loss: 0.1439 - val_dense_6_loss: 0.6897 - val_dense_7_loss: 0.2576 - val_dense_8_loss: 0.5670 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3643 - dense_loss: 0.3685 - dense_1_loss: 0.1743 - dense_2_loss: 0.2821 - dense_3_loss: 0.6465 - dense_4_loss: 0.3435 - dense_5_loss: 0.1484 - dense_6_loss: 0.6830 - dense_7_loss: 0.1883 - dense_8_loss: 0.5298 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5101 - val_dense_loss: 0.4060 - val_dense_1_loss: 0.1600 - val_dense_2_loss: 0.2559 - val_dense_3_loss: 0.6881 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1438 - val_dense_6_loss: 0.6895 - val_dense_7_loss: 0.2575 - val_dense_8_loss: 0.5691 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3632 - dense_loss: 0.3685 - dense_1_loss: 0.1743 - dense_2_loss: 0.2819 - dense_3_loss: 0.6451 - dense_4_loss: 0.3430 - dense_5_loss: 0.1482 - dense_6_loss: 0.6830 - dense_7_loss: 0.1883 - dense_8_loss: 0.5309 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6585 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5078 - val_dense_loss: 0.4063 - val_dense_1_loss: 0.1601 - val_dense_2_loss: 0.2556 - val_dense_3_loss: 0.6845 - val_dense_4_loss: 0.3402 - val_dense_5_loss: 0.1437 - val_dense_6_loss: 0.6894 - val_dense_7_loss: 0.2573 - val_dense_8_loss: 0.5708 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3623 - dense_loss: 0.3685 - dense_1_loss: 0.1744 - dense_2_loss: 0.2818 - dense_3_loss: 0.6435 - dense_4_loss: 0.3429 - dense_5_loss: 0.1480 - dense_6_loss: 0.6832 - dense_7_loss: 0.1883 - dense_8_loss: 0.5318 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5052 - val_dense_loss: 0.4065 - val_dense_1_loss: 0.1601 - val_dense_2_loss: 0.2552 - val_dense_3_loss: 0.6809 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6895 - val_dense_7_loss: 0.2572 - val_dense_8_loss: 0.5717 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3617 - dense_loss: 0.3685 - dense_1_loss: 0.1744 - dense_2_loss: 0.2816 - dense_3_loss: 0.6423 - dense_4_loss: 0.3431 - dense_5_loss: 0.1479 - dense_6_loss: 0.6834 - dense_7_loss: 0.1883 - dense_8_loss: 0.5323 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.5023 - val_dense_loss: 0.4066 - val_dense_1_loss: 0.1601 - val_dense_2_loss: 0.2549 - val_dense_3_loss: 0.6777 - val_dense_4_loss: 0.3406 - val_dense_5_loss: 0.1435 - val_dense_6_loss: 0.6896 - val_dense_7_loss: 0.2571 - val_dense_8_loss: 0.5720 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3612 - dense_loss: 0.3684 - dense_1_loss: 0.1744 - dense_2_loss: 0.2815 - dense_3_loss: 0.6415 - dense_4_loss: 0.3434 - dense_5_loss: 0.1478 - dense_6_loss: 0.6835 - dense_7_loss: 0.1883 - dense_8_loss: 0.5325 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4994 - val_dense_loss: 0.4067 - val_dense_1_loss: 0.1600 - val_dense_2_loss: 0.2547 - val_dense_3_loss: 0.6752 - val_dense_4_loss: 0.3410 - val_dense_5_loss: 0.1435 - val_dense_6_loss: 0.6897 - val_dense_7_loss: 0.2571 - val_dense_8_loss: 0.5716 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3609 - dense_loss: 0.3684 - dense_1_loss: 0.1744 - dense_2_loss: 0.2814 - dense_3_loss: 0.6412 - dense_4_loss: 0.3438 - dense_5_loss: 0.1478 - dense_6_loss: 0.6835 - dense_7_loss: 0.1883 - dense_8_loss: 0.5322 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4965 - val_dense_loss: 0.4066 - val_dense_1_loss: 0.1600 - val_dense_2_loss: 0.2544 - val_dense_3_loss: 0.6733 - val_dense_4_loss: 0.3413 - val_dense_5_loss: 0.1435 - val_dense_6_loss: 0.6898 - val_dense_7_loss: 0.2570 - val_dense_8_loss: 0.5706 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3605 - dense_loss: 0.3684 - dense_1_loss: 0.1743 - dense_2_loss: 0.2813 - dense_3_loss: 0.6414 - dense_4_loss: 0.3442 - dense_5_loss: 0.1477 - dense_6_loss: 0.6834 - dense_7_loss: 0.1883 - dense_8_loss: 0.5315 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4938 - val_dense_loss: 0.4064 - val_dense_1_loss: 0.1599 - val_dense_2_loss: 0.2542 - val_dense_3_loss: 0.6721 - val_dense_4_loss: 0.3416 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6898 - val_dense_7_loss: 0.2570 - val_dense_8_loss: 0.5692 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3601 - dense_loss: 0.3683 - dense_1_loss: 0.1743 - dense_2_loss: 0.2812 - dense_3_loss: 0.6418 - dense_4_loss: 0.3446 - dense_5_loss: 0.1477 - dense_6_loss: 0.6832 - dense_7_loss: 0.1883 - dense_8_loss: 0.5307 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4913 - val_dense_loss: 0.4062 - val_dense_1_loss: 0.1598 - val_dense_2_loss: 0.2540 - val_dense_3_loss: 0.6713 - val_dense_4_loss: 0.3418 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6899 - val_dense_7_loss: 0.2570 - val_dense_8_loss: 0.5677 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3595 - dense_loss: 0.3682 - dense_1_loss: 0.1743 - dense_2_loss: 0.2812 - dense_3_loss: 0.6423 - dense_4_loss: 0.3447 - dense_5_loss: 0.1477 - dense_6_loss: 0.6830 - dense_7_loss: 0.1883 - dense_8_loss: 0.5298 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4892 - val_dense_loss: 0.4059 - val_dense_1_loss: 0.1597 - val_dense_2_loss: 0.2538 - val_dense_3_loss: 0.6710 - val_dense_4_loss: 0.3419 - val_dense_5_loss: 0.1437 - val_dense_6_loss: 0.6901 - val_dense_7_loss: 0.2571 - val_dense_8_loss: 0.5661 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3588 - dense_loss: 0.3682 - dense_1_loss: 0.1742 - dense_2_loss: 0.2812 - dense_3_loss: 0.6426 - dense_4_loss: 0.3448 - dense_5_loss: 0.1478 - dense_6_loss: 0.6828 - dense_7_loss: 0.1883 - dense_8_loss: 0.5290 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4875 - val_dense_loss: 0.4057 - val_dense_1_loss: 0.1596 - val_dense_2_loss: 0.2537 - val_dense_3_loss: 0.6709 - val_dense_4_loss: 0.3418 - val_dense_5_loss: 0.1437 - val_dense_6_loss: 0.6904 - val_dense_7_loss: 0.2571 - val_dense_8_loss: 0.5646 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3581 - dense_loss: 0.3682 - dense_1_loss: 0.1742 - dense_2_loss: 0.2812 - dense_3_loss: 0.6427 - dense_4_loss: 0.3446 - dense_5_loss: 0.1478 - dense_6_loss: 0.6827 - dense_7_loss: 0.1883 - dense_8_loss: 0.5284 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4862 - val_dense_loss: 0.4055 - val_dense_1_loss: 0.1595 - val_dense_2_loss: 0.2536 - val_dense_3_loss: 0.6711 - val_dense_4_loss: 0.3416 - val_dense_5_loss: 0.1438 - val_dense_6_loss: 0.6906 - val_dense_7_loss: 0.2572 - val_dense_8_loss: 0.5633 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3573 - dense_loss: 0.3682 - dense_1_loss: 0.1742 - dense_2_loss: 0.2812 - dense_3_loss: 0.6426 - dense_4_loss: 0.3444 - dense_5_loss: 0.1478 - dense_6_loss: 0.6828 - dense_7_loss: 0.1882 - dense_8_loss: 0.5280 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4855 - val_dense_loss: 0.4053 - val_dense_1_loss: 0.1595 - val_dense_2_loss: 0.2535 - val_dense_3_loss: 0.6714 - val_dense_4_loss: 0.3413 - val_dense_5_loss: 0.1438 - val_dense_6_loss: 0.6909 - val_dense_7_loss: 0.2574 - val_dense_8_loss: 0.5623 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3565 - dense_loss: 0.3682 - dense_1_loss: 0.1741 - dense_2_loss: 0.2812 - dense_3_loss: 0.6423 - dense_4_loss: 0.3441 - dense_5_loss: 0.1479 - dense_6_loss: 0.6828 - dense_7_loss: 0.1882 - dense_8_loss: 0.5278 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4852 - val_dense_loss: 0.4052 - val_dense_1_loss: 0.1594 - val_dense_2_loss: 0.2535 - val_dense_3_loss: 0.6720 - val_dense_4_loss: 0.3410 - val_dense_5_loss: 0.1438 - val_dense_6_loss: 0.6912 - val_dense_7_loss: 0.2575 - val_dense_8_loss: 0.5617 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7535\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3558 - dense_loss: 0.3682 - dense_1_loss: 0.1741 - dense_2_loss: 0.2812 - dense_3_loss: 0.6418 - dense_4_loss: 0.3438 - dense_5_loss: 0.1479 - dense_6_loss: 0.6828 - dense_7_loss: 0.1882 - dense_8_loss: 0.5279 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7786 - val_loss: 3.4855 - val_dense_loss: 0.4051 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2535 - val_dense_3_loss: 0.6728 - val_dense_4_loss: 0.3407 - val_dense_5_loss: 0.1438 - val_dense_6_loss: 0.6913 - val_dense_7_loss: 0.2577 - val_dense_8_loss: 0.5612 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3553 - dense_loss: 0.3682 - dense_1_loss: 0.1741 - dense_2_loss: 0.2811 - dense_3_loss: 0.6414 - dense_4_loss: 0.3434 - dense_5_loss: 0.1479 - dense_6_loss: 0.6829 - dense_7_loss: 0.1882 - dense_8_loss: 0.5281 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4862 - val_dense_loss: 0.4050 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2535 - val_dense_3_loss: 0.6739 - val_dense_4_loss: 0.3405 - val_dense_5_loss: 0.1438 - val_dense_6_loss: 0.6913 - val_dense_7_loss: 0.2579 - val_dense_8_loss: 0.5610 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3549 - dense_loss: 0.3682 - dense_1_loss: 0.1741 - dense_2_loss: 0.2811 - dense_3_loss: 0.6411 - dense_4_loss: 0.3431 - dense_5_loss: 0.1479 - dense_6_loss: 0.6828 - dense_7_loss: 0.1882 - dense_8_loss: 0.5283 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4872 - val_dense_loss: 0.4050 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2535 - val_dense_3_loss: 0.6751 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1438 - val_dense_6_loss: 0.6913 - val_dense_7_loss: 0.2580 - val_dense_8_loss: 0.5609 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3546 - dense_loss: 0.3681 - dense_1_loss: 0.1741 - dense_2_loss: 0.2811 - dense_3_loss: 0.6410 - dense_4_loss: 0.3429 - dense_5_loss: 0.1479 - dense_6_loss: 0.6828 - dense_7_loss: 0.1881 - dense_8_loss: 0.5286 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4884 - val_dense_loss: 0.4051 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2535 - val_dense_3_loss: 0.6763 - val_dense_4_loss: 0.3402 - val_dense_5_loss: 0.1438 - val_dense_6_loss: 0.6912 - val_dense_7_loss: 0.2582 - val_dense_8_loss: 0.5609 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3545 - dense_loss: 0.3681 - dense_1_loss: 0.1741 - dense_2_loss: 0.2811 - dense_3_loss: 0.6410 - dense_4_loss: 0.3428 - dense_5_loss: 0.1479 - dense_6_loss: 0.6827 - dense_7_loss: 0.1881 - dense_8_loss: 0.5288 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4897 - val_dense_loss: 0.4052 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2535 - val_dense_3_loss: 0.6774 - val_dense_4_loss: 0.3402 - val_dense_5_loss: 0.1438 - val_dense_6_loss: 0.6910 - val_dense_7_loss: 0.2583 - val_dense_8_loss: 0.5609 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3544 - dense_loss: 0.3680 - dense_1_loss: 0.1741 - dense_2_loss: 0.2810 - dense_3_loss: 0.6411 - dense_4_loss: 0.3427 - dense_5_loss: 0.1479 - dense_6_loss: 0.6826 - dense_7_loss: 0.1881 - dense_8_loss: 0.5288 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4909 - val_dense_loss: 0.4053 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2536 - val_dense_3_loss: 0.6784 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1438 - val_dense_6_loss: 0.6909 - val_dense_7_loss: 0.2584 - val_dense_8_loss: 0.5610 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3543 - dense_loss: 0.3680 - dense_1_loss: 0.1741 - dense_2_loss: 0.2810 - dense_3_loss: 0.6412 - dense_4_loss: 0.3427 - dense_5_loss: 0.1478 - dense_6_loss: 0.6826 - dense_7_loss: 0.1881 - dense_8_loss: 0.5287 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4920 - val_dense_loss: 0.4055 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2536 - val_dense_3_loss: 0.6790 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.1437 - val_dense_6_loss: 0.6909 - val_dense_7_loss: 0.2585 - val_dense_8_loss: 0.5611 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3542 - dense_loss: 0.3679 - dense_1_loss: 0.1741 - dense_2_loss: 0.2809 - dense_3_loss: 0.6414 - dense_4_loss: 0.3428 - dense_5_loss: 0.1478 - dense_6_loss: 0.6826 - dense_7_loss: 0.1881 - dense_8_loss: 0.5286 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4928 - val_dense_loss: 0.4057 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2537 - val_dense_3_loss: 0.6793 - val_dense_4_loss: 0.3405 - val_dense_5_loss: 0.1437 - val_dense_6_loss: 0.6908 - val_dense_7_loss: 0.2586 - val_dense_8_loss: 0.5612 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3540 - dense_loss: 0.3679 - dense_1_loss: 0.1741 - dense_2_loss: 0.2809 - dense_3_loss: 0.6414 - dense_4_loss: 0.3429 - dense_5_loss: 0.1478 - dense_6_loss: 0.6826 - dense_7_loss: 0.1881 - dense_8_loss: 0.5283 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4935 - val_dense_loss: 0.4060 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2538 - val_dense_3_loss: 0.6792 - val_dense_4_loss: 0.3406 - val_dense_5_loss: 0.1437 - val_dense_6_loss: 0.6908 - val_dense_7_loss: 0.2586 - val_dense_8_loss: 0.5615 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3537 - dense_loss: 0.3679 - dense_1_loss: 0.1741 - dense_2_loss: 0.2808 - dense_3_loss: 0.6414 - dense_4_loss: 0.3430 - dense_5_loss: 0.1478 - dense_6_loss: 0.6826 - dense_7_loss: 0.1881 - dense_8_loss: 0.5281 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4939 - val_dense_loss: 0.4062 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2539 - val_dense_3_loss: 0.6788 - val_dense_4_loss: 0.3407 - val_dense_5_loss: 0.1437 - val_dense_6_loss: 0.6909 - val_dense_7_loss: 0.2587 - val_dense_8_loss: 0.5618 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3534 - dense_loss: 0.3679 - dense_1_loss: 0.1741 - dense_2_loss: 0.2808 - dense_3_loss: 0.6413 - dense_4_loss: 0.3430 - dense_5_loss: 0.1478 - dense_6_loss: 0.6826 - dense_7_loss: 0.1881 - dense_8_loss: 0.5279 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4941 - val_dense_loss: 0.4064 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2540 - val_dense_3_loss: 0.6782 - val_dense_4_loss: 0.3408 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6909 - val_dense_7_loss: 0.2587 - val_dense_8_loss: 0.5622 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3531 - dense_loss: 0.3679 - dense_1_loss: 0.1741 - dense_2_loss: 0.2808 - dense_3_loss: 0.6411 - dense_4_loss: 0.3431 - dense_5_loss: 0.1478 - dense_6_loss: 0.6826 - dense_7_loss: 0.1881 - dense_8_loss: 0.5277 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4942 - val_dense_loss: 0.4066 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2541 - val_dense_3_loss: 0.6775 - val_dense_4_loss: 0.3408 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6910 - val_dense_7_loss: 0.2587 - val_dense_8_loss: 0.5626 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3528 - dense_loss: 0.3679 - dense_1_loss: 0.1741 - dense_2_loss: 0.2807 - dense_3_loss: 0.6410 - dense_4_loss: 0.3430 - dense_5_loss: 0.1478 - dense_6_loss: 0.6825 - dense_7_loss: 0.1881 - dense_8_loss: 0.5277 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4942 - val_dense_loss: 0.4067 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2542 - val_dense_3_loss: 0.6767 - val_dense_4_loss: 0.3407 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6911 - val_dense_7_loss: 0.2587 - val_dense_8_loss: 0.5631 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3526 - dense_loss: 0.3679 - dense_1_loss: 0.1741 - dense_2_loss: 0.2807 - dense_3_loss: 0.6409 - dense_4_loss: 0.3430 - dense_5_loss: 0.1477 - dense_6_loss: 0.6825 - dense_7_loss: 0.1881 - dense_8_loss: 0.5276 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4941 - val_dense_loss: 0.4068 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2543 - val_dense_3_loss: 0.6760 - val_dense_4_loss: 0.3406 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6912 - val_dense_7_loss: 0.2587 - val_dense_8_loss: 0.5636 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3524 - dense_loss: 0.3679 - dense_1_loss: 0.1741 - dense_2_loss: 0.2807 - dense_3_loss: 0.6408 - dense_4_loss: 0.3429 - dense_5_loss: 0.1477 - dense_6_loss: 0.6825 - dense_7_loss: 0.1880 - dense_8_loss: 0.5277 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4940 - val_dense_loss: 0.4068 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2544 - val_dense_3_loss: 0.6753 - val_dense_4_loss: 0.3406 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6914 - val_dense_7_loss: 0.2587 - val_dense_8_loss: 0.5640 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3523 - dense_loss: 0.3679 - dense_1_loss: 0.1741 - dense_2_loss: 0.2807 - dense_3_loss: 0.6408 - dense_4_loss: 0.3428 - dense_5_loss: 0.1477 - dense_6_loss: 0.6824 - dense_7_loss: 0.1880 - dense_8_loss: 0.5277 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4939 - val_dense_loss: 0.4067 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2544 - val_dense_3_loss: 0.6748 - val_dense_4_loss: 0.3405 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6915 - val_dense_7_loss: 0.2588 - val_dense_8_loss: 0.5644 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3522 - dense_loss: 0.3678 - dense_1_loss: 0.1741 - dense_2_loss: 0.2807 - dense_3_loss: 0.6409 - dense_4_loss: 0.3427 - dense_5_loss: 0.1477 - dense_6_loss: 0.6824 - dense_7_loss: 0.1880 - dense_8_loss: 0.5278 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4937 - val_dense_loss: 0.4066 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2544 - val_dense_3_loss: 0.6745 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6916 - val_dense_7_loss: 0.2588 - val_dense_8_loss: 0.5646 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3522 - dense_loss: 0.3678 - dense_1_loss: 0.1741 - dense_2_loss: 0.2807 - dense_3_loss: 0.6409 - dense_4_loss: 0.3426 - dense_5_loss: 0.1477 - dense_6_loss: 0.6824 - dense_7_loss: 0.1880 - dense_8_loss: 0.5278 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4935 - val_dense_loss: 0.4064 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2544 - val_dense_3_loss: 0.6743 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6917 - val_dense_7_loss: 0.2588 - val_dense_8_loss: 0.5647 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3521 - dense_loss: 0.3678 - dense_1_loss: 0.1741 - dense_2_loss: 0.2807 - dense_3_loss: 0.6409 - dense_4_loss: 0.3426 - dense_5_loss: 0.1477 - dense_6_loss: 0.6824 - dense_7_loss: 0.1880 - dense_8_loss: 0.5279 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4933 - val_dense_loss: 0.4062 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2544 - val_dense_3_loss: 0.6743 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6918 - val_dense_7_loss: 0.2588 - val_dense_8_loss: 0.5647 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3519 - dense_loss: 0.3677 - dense_1_loss: 0.1741 - dense_2_loss: 0.2807 - dense_3_loss: 0.6409 - dense_4_loss: 0.3425 - dense_5_loss: 0.1477 - dense_6_loss: 0.6824 - dense_7_loss: 0.1880 - dense_8_loss: 0.5278 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4930 - val_dense_loss: 0.4061 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2544 - val_dense_3_loss: 0.6743 - val_dense_4_loss: 0.3402 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6918 - val_dense_7_loss: 0.2588 - val_dense_8_loss: 0.5647 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3517 - dense_loss: 0.3677 - dense_1_loss: 0.1741 - dense_2_loss: 0.2806 - dense_3_loss: 0.6409 - dense_4_loss: 0.3425 - dense_5_loss: 0.1477 - dense_6_loss: 0.6824 - dense_7_loss: 0.1880 - dense_8_loss: 0.5278 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4928 - val_dense_loss: 0.4059 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2543 - val_dense_3_loss: 0.6746 - val_dense_4_loss: 0.3402 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6918 - val_dense_7_loss: 0.2588 - val_dense_8_loss: 0.5645 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3516 - dense_loss: 0.3677 - dense_1_loss: 0.1741 - dense_2_loss: 0.2806 - dense_3_loss: 0.6408 - dense_4_loss: 0.3425 - dense_5_loss: 0.1477 - dense_6_loss: 0.6824 - dense_7_loss: 0.1880 - dense_8_loss: 0.5277 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4926 - val_dense_loss: 0.4057 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2543 - val_dense_3_loss: 0.6749 - val_dense_4_loss: 0.3402 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6918 - val_dense_7_loss: 0.2588 - val_dense_8_loss: 0.5642 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3514 - dense_loss: 0.3676 - dense_1_loss: 0.1741 - dense_2_loss: 0.2806 - dense_3_loss: 0.6408 - dense_4_loss: 0.3425 - dense_5_loss: 0.1477 - dense_6_loss: 0.6823 - dense_7_loss: 0.1880 - dense_8_loss: 0.5277 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4925 - val_dense_loss: 0.4056 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2542 - val_dense_3_loss: 0.6753 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6917 - val_dense_7_loss: 0.2588 - val_dense_8_loss: 0.5640 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3512 - dense_loss: 0.3676 - dense_1_loss: 0.1741 - dense_2_loss: 0.2806 - dense_3_loss: 0.6407 - dense_4_loss: 0.3425 - dense_5_loss: 0.1477 - dense_6_loss: 0.6823 - dense_7_loss: 0.1879 - dense_8_loss: 0.5276 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4925 - val_dense_loss: 0.4054 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2541 - val_dense_3_loss: 0.6757 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6917 - val_dense_7_loss: 0.2587 - val_dense_8_loss: 0.5638 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3511 - dense_loss: 0.3676 - dense_1_loss: 0.1741 - dense_2_loss: 0.2806 - dense_3_loss: 0.6407 - dense_4_loss: 0.3425 - dense_5_loss: 0.1477 - dense_6_loss: 0.6823 - dense_7_loss: 0.1879 - dense_8_loss: 0.5276 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4926 - val_dense_loss: 0.4054 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2541 - val_dense_3_loss: 0.6761 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6917 - val_dense_7_loss: 0.2587 - val_dense_8_loss: 0.5635 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3510 - dense_loss: 0.3676 - dense_1_loss: 0.1741 - dense_2_loss: 0.2806 - dense_3_loss: 0.6407 - dense_4_loss: 0.3425 - dense_5_loss: 0.1477 - dense_6_loss: 0.6823 - dense_7_loss: 0.1879 - dense_8_loss: 0.5275 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4927 - val_dense_loss: 0.4053 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2540 - val_dense_3_loss: 0.6765 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6917 - val_dense_7_loss: 0.2587 - val_dense_8_loss: 0.5633 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3509 - dense_loss: 0.3676 - dense_1_loss: 0.1741 - dense_2_loss: 0.2805 - dense_3_loss: 0.6407 - dense_4_loss: 0.3425 - dense_5_loss: 0.1477 - dense_6_loss: 0.6823 - dense_7_loss: 0.1879 - dense_8_loss: 0.5275 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4928 - val_dense_loss: 0.4053 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2540 - val_dense_3_loss: 0.6769 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6917 - val_dense_7_loss: 0.2586 - val_dense_8_loss: 0.5632 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3509 - dense_loss: 0.3676 - dense_1_loss: 0.1741 - dense_2_loss: 0.2805 - dense_3_loss: 0.6407 - dense_4_loss: 0.3425 - dense_5_loss: 0.1477 - dense_6_loss: 0.6823 - dense_7_loss: 0.1879 - dense_8_loss: 0.5275 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4929 - val_dense_loss: 0.4054 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2539 - val_dense_3_loss: 0.6771 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6917 - val_dense_7_loss: 0.2585 - val_dense_8_loss: 0.5631 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3508 - dense_loss: 0.3676 - dense_1_loss: 0.1741 - dense_2_loss: 0.2805 - dense_3_loss: 0.6407 - dense_4_loss: 0.3424 - dense_5_loss: 0.1477 - dense_6_loss: 0.6823 - dense_7_loss: 0.1879 - dense_8_loss: 0.5275 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9184 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4930 - val_dense_loss: 0.4054 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2539 - val_dense_3_loss: 0.6772 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6918 - val_dense_7_loss: 0.2585 - val_dense_8_loss: 0.5630 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3507 - dense_loss: 0.3676 - dense_1_loss: 0.1741 - dense_2_loss: 0.2805 - dense_3_loss: 0.6407 - dense_4_loss: 0.3424 - dense_5_loss: 0.1477 - dense_6_loss: 0.6823 - dense_7_loss: 0.1879 - dense_8_loss: 0.5275 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4931 - val_dense_loss: 0.4055 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2539 - val_dense_3_loss: 0.6773 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6918 - val_dense_7_loss: 0.2584 - val_dense_8_loss: 0.5630 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3506 - dense_loss: 0.3676 - dense_1_loss: 0.1741 - dense_2_loss: 0.2805 - dense_3_loss: 0.6407 - dense_4_loss: 0.3424 - dense_5_loss: 0.1477 - dense_6_loss: 0.6822 - dense_7_loss: 0.1879 - dense_8_loss: 0.5275 - dense_acc: 0.8788 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4931 - val_dense_loss: 0.4056 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2539 - val_dense_3_loss: 0.6772 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6919 - val_dense_7_loss: 0.2583 - val_dense_8_loss: 0.5631 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3505 - dense_loss: 0.3675 - dense_1_loss: 0.1741 - dense_2_loss: 0.2805 - dense_3_loss: 0.6407 - dense_4_loss: 0.3423 - dense_5_loss: 0.1478 - dense_6_loss: 0.6822 - dense_7_loss: 0.1879 - dense_8_loss: 0.5275 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4932 - val_dense_loss: 0.4057 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2539 - val_dense_3_loss: 0.6770 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6920 - val_dense_7_loss: 0.2583 - val_dense_8_loss: 0.5631 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3504 - dense_loss: 0.3675 - dense_1_loss: 0.1741 - dense_2_loss: 0.2805 - dense_3_loss: 0.6406 - dense_4_loss: 0.3423 - dense_5_loss: 0.1478 - dense_6_loss: 0.6822 - dense_7_loss: 0.1878 - dense_8_loss: 0.5275 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4933 - val_dense_loss: 0.4059 - val_dense_1_loss: 0.1594 - val_dense_2_loss: 0.2539 - val_dense_3_loss: 0.6768 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6920 - val_dense_7_loss: 0.2582 - val_dense_8_loss: 0.5632 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3502 - dense_loss: 0.3675 - dense_1_loss: 0.1741 - dense_2_loss: 0.2805 - dense_3_loss: 0.6406 - dense_4_loss: 0.3423 - dense_5_loss: 0.1478 - dense_6_loss: 0.6822 - dense_7_loss: 0.1878 - dense_8_loss: 0.5275 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4933 - val_dense_loss: 0.4060 - val_dense_1_loss: 0.1594 - val_dense_2_loss: 0.2539 - val_dense_3_loss: 0.6766 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6921 - val_dense_7_loss: 0.2582 - val_dense_8_loss: 0.5633 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3501 - dense_loss: 0.3675 - dense_1_loss: 0.1741 - dense_2_loss: 0.2805 - dense_3_loss: 0.6406 - dense_4_loss: 0.3422 - dense_5_loss: 0.1478 - dense_6_loss: 0.6822 - dense_7_loss: 0.1878 - dense_8_loss: 0.5275 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6597 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4935 - val_dense_loss: 0.4061 - val_dense_1_loss: 0.1594 - val_dense_2_loss: 0.2540 - val_dense_3_loss: 0.6763 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6922 - val_dense_7_loss: 0.2582 - val_dense_8_loss: 0.5635 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3500 - dense_loss: 0.3675 - dense_1_loss: 0.1741 - dense_2_loss: 0.2805 - dense_3_loss: 0.6406 - dense_4_loss: 0.3422 - dense_5_loss: 0.1478 - dense_6_loss: 0.6822 - dense_7_loss: 0.1878 - dense_8_loss: 0.5275 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4936 - val_dense_loss: 0.4062 - val_dense_1_loss: 0.1594 - val_dense_2_loss: 0.2540 - val_dense_3_loss: 0.6762 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6922 - val_dense_7_loss: 0.2581 - val_dense_8_loss: 0.5636 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3500 - dense_loss: 0.3675 - dense_1_loss: 0.1741 - dense_2_loss: 0.2805 - dense_3_loss: 0.6406 - dense_4_loss: 0.3422 - dense_5_loss: 0.1478 - dense_6_loss: 0.6821 - dense_7_loss: 0.1878 - dense_8_loss: 0.5275 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4937 - val_dense_loss: 0.4063 - val_dense_1_loss: 0.1594 - val_dense_2_loss: 0.2540 - val_dense_3_loss: 0.6760 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6922 - val_dense_7_loss: 0.2582 - val_dense_8_loss: 0.5638 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3499 - dense_loss: 0.3675 - dense_1_loss: 0.1741 - dense_2_loss: 0.2804 - dense_3_loss: 0.6406 - dense_4_loss: 0.3422 - dense_5_loss: 0.1478 - dense_6_loss: 0.6821 - dense_7_loss: 0.1878 - dense_8_loss: 0.5274 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4939 - val_dense_loss: 0.4063 - val_dense_1_loss: 0.1594 - val_dense_2_loss: 0.2540 - val_dense_3_loss: 0.6759 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6922 - val_dense_7_loss: 0.2582 - val_dense_8_loss: 0.5639 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3498 - dense_loss: 0.3675 - dense_1_loss: 0.1741 - dense_2_loss: 0.2804 - dense_3_loss: 0.6406 - dense_4_loss: 0.3422 - dense_5_loss: 0.1478 - dense_6_loss: 0.6821 - dense_7_loss: 0.1878 - dense_8_loss: 0.5274 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4941 - val_dense_loss: 0.4063 - val_dense_1_loss: 0.1594 - val_dense_2_loss: 0.2540 - val_dense_3_loss: 0.6759 - val_dense_4_loss: 0.3403 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6922 - val_dense_7_loss: 0.2582 - val_dense_8_loss: 0.5640 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3497 - dense_loss: 0.3674 - dense_1_loss: 0.1741 - dense_2_loss: 0.2804 - dense_3_loss: 0.6405 - dense_4_loss: 0.3422 - dense_5_loss: 0.1478 - dense_6_loss: 0.6821 - dense_7_loss: 0.1877 - dense_8_loss: 0.5274 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4943 - val_dense_loss: 0.4063 - val_dense_1_loss: 0.1594 - val_dense_2_loss: 0.2540 - val_dense_3_loss: 0.6760 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6922 - val_dense_7_loss: 0.2583 - val_dense_8_loss: 0.5641 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3496 - dense_loss: 0.3674 - dense_1_loss: 0.1741 - dense_2_loss: 0.2804 - dense_3_loss: 0.6405 - dense_4_loss: 0.3421 - dense_5_loss: 0.1478 - dense_6_loss: 0.6821 - dense_7_loss: 0.1877 - dense_8_loss: 0.5274 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4944 - val_dense_loss: 0.4062 - val_dense_1_loss: 0.1594 - val_dense_2_loss: 0.2541 - val_dense_3_loss: 0.6761 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6922 - val_dense_7_loss: 0.2584 - val_dense_8_loss: 0.5642 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3495 - dense_loss: 0.3674 - dense_1_loss: 0.1741 - dense_2_loss: 0.2804 - dense_3_loss: 0.6405 - dense_4_loss: 0.3421 - dense_5_loss: 0.1478 - dense_6_loss: 0.6821 - dense_7_loss: 0.1877 - dense_8_loss: 0.5274 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4946 - val_dense_loss: 0.4062 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2541 - val_dense_3_loss: 0.6762 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6922 - val_dense_7_loss: 0.2584 - val_dense_8_loss: 0.5643 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3495 - dense_loss: 0.3674 - dense_1_loss: 0.1741 - dense_2_loss: 0.2804 - dense_3_loss: 0.6405 - dense_4_loss: 0.3421 - dense_5_loss: 0.1478 - dense_6_loss: 0.6820 - dense_7_loss: 0.1877 - dense_8_loss: 0.5274 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4948 - val_dense_loss: 0.4061 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2541 - val_dense_3_loss: 0.6764 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6922 - val_dense_7_loss: 0.2585 - val_dense_8_loss: 0.5643 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3494 - dense_loss: 0.3674 - dense_1_loss: 0.1741 - dense_2_loss: 0.2804 - dense_3_loss: 0.6405 - dense_4_loss: 0.3421 - dense_5_loss: 0.1478 - dense_6_loss: 0.6820 - dense_7_loss: 0.1877 - dense_8_loss: 0.5274 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4950 - val_dense_loss: 0.4060 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2541 - val_dense_3_loss: 0.6765 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6922 - val_dense_7_loss: 0.2586 - val_dense_8_loss: 0.5643 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3493 - dense_loss: 0.3674 - dense_1_loss: 0.1741 - dense_2_loss: 0.2804 - dense_3_loss: 0.6405 - dense_4_loss: 0.3421 - dense_5_loss: 0.1478 - dense_6_loss: 0.6820 - dense_7_loss: 0.1877 - dense_8_loss: 0.5274 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4951 - val_dense_loss: 0.4059 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2541 - val_dense_3_loss: 0.6767 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6922 - val_dense_7_loss: 0.2587 - val_dense_8_loss: 0.5643 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3492 - dense_loss: 0.3674 - dense_1_loss: 0.1741 - dense_2_loss: 0.2804 - dense_3_loss: 0.6405 - dense_4_loss: 0.3420 - dense_5_loss: 0.1478 - dense_6_loss: 0.6820 - dense_7_loss: 0.1877 - dense_8_loss: 0.5274 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4953 - val_dense_loss: 0.4058 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2541 - val_dense_3_loss: 0.6769 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6923 - val_dense_7_loss: 0.2587 - val_dense_8_loss: 0.5643 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3491 - dense_loss: 0.3673 - dense_1_loss: 0.1741 - dense_2_loss: 0.2804 - dense_3_loss: 0.6405 - dense_4_loss: 0.3420 - dense_5_loss: 0.1478 - dense_6_loss: 0.6820 - dense_7_loss: 0.1876 - dense_8_loss: 0.5274 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4954 - val_dense_loss: 0.4057 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2541 - val_dense_3_loss: 0.6770 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6923 - val_dense_7_loss: 0.2588 - val_dense_8_loss: 0.5643 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3490 - dense_loss: 0.3673 - dense_1_loss: 0.1741 - dense_2_loss: 0.2804 - dense_3_loss: 0.6404 - dense_4_loss: 0.3420 - dense_5_loss: 0.1478 - dense_6_loss: 0.6820 - dense_7_loss: 0.1876 - dense_8_loss: 0.5274 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4954 - val_dense_loss: 0.4057 - val_dense_1_loss: 0.1593 - val_dense_2_loss: 0.2541 - val_dense_3_loss: 0.6771 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6923 - val_dense_7_loss: 0.2588 - val_dense_8_loss: 0.5643 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3489 - dense_loss: 0.3673 - dense_1_loss: 0.1741 - dense_2_loss: 0.2804 - dense_3_loss: 0.6404 - dense_4_loss: 0.3420 - dense_5_loss: 0.1478 - dense_6_loss: 0.6820 - dense_7_loss: 0.1876 - dense_8_loss: 0.5274 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4955 - val_dense_loss: 0.4057 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2540 - val_dense_3_loss: 0.6771 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6924 - val_dense_7_loss: 0.2589 - val_dense_8_loss: 0.5643 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3488 - dense_loss: 0.3673 - dense_1_loss: 0.1741 - dense_2_loss: 0.2804 - dense_3_loss: 0.6404 - dense_4_loss: 0.3419 - dense_5_loss: 0.1478 - dense_6_loss: 0.6819 - dense_7_loss: 0.1876 - dense_8_loss: 0.5274 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4955 - val_dense_loss: 0.4057 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2540 - val_dense_3_loss: 0.6771 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6924 - val_dense_7_loss: 0.2589 - val_dense_8_loss: 0.5642 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.3488 - dense_loss: 0.3673 - dense_1_loss: 0.1741 - dense_2_loss: 0.2804 - dense_3_loss: 0.6404 - dense_4_loss: 0.3419 - dense_5_loss: 0.1478 - dense_6_loss: 0.6819 - dense_7_loss: 0.1876 - dense_8_loss: 0.5274 - dense_acc: 0.8800 - dense_1_acc: 0.9580 - dense_2_acc: 0.9196 - dense_3_acc: 0.6608 - dense_4_acc: 0.8916 - dense_5_acc: 0.9662 - dense_6_acc: 0.5699 - dense_7_acc: 0.9534 - dense_8_acc: 0.7797 - val_loss: 3.4955 - val_dense_loss: 0.4057 - val_dense_1_loss: 0.1592 - val_dense_2_loss: 0.2540 - val_dense_3_loss: 0.6770 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.1436 - val_dense_6_loss: 0.6924 - val_dense_7_loss: 0.2589 - val_dense_8_loss: 0.5642 - val_dense_acc: 0.8605 - val_dense_1_acc: 0.9628 - val_dense_2_acc: 0.9302 - val_dense_3_acc: 0.6512 - val_dense_4_acc: 0.8930 - val_dense_5_acc: 0.9674 - val_dense_6_acc: 0.5488 - val_dense_7_acc: 0.9302 - val_dense_8_acc: 0.7488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za2xNuSq70Jg",
        "outputId": "ff61775e-0bea-4cf6-9c2a-8840f3aa6298"
      },
      "source": [
        "score = model.evaluate(x=X_test, y=[y1_test, y2_test, y3_test, y4_test, y5_test, y6_test, y7_test, y8_test, y9_test], verbose=1)\n",
        "\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 66ms/step - loss: 6.0857 - dense_loss: 0.6821 - dense_1_loss: 0.6666 - dense_2_loss: 0.6702 - dense_3_loss: 0.6908 - dense_4_loss: 0.6739 - dense_5_loss: 0.6672 - dense_6_loss: 0.6929 - dense_7_loss: 0.6643 - dense_8_loss: 0.6775 - dense_acc: 0.8922 - dense_1_acc: 0.9665 - dense_2_acc: 0.9405 - dense_3_acc: 0.6431 - dense_4_acc: 0.8922 - dense_5_acc: 0.9814 - dense_6_acc: 0.5130 - dense_7_acc: 0.9591 - dense_8_acc: 0.7398\n",
            "Test Score: 6.085727691650391\n",
            "Test Accuracy: 0.6821446418762207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P5IH7FT8XYn",
        "outputId": "48fb9f86-0980-4e21-ff2b-1ab449b4a21a"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "export_dir = 'saved_model/1'\n",
        "tf.saved_model.save(model, export_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/1/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSUsOMg79y-d"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8Ms8mVV-HM4",
        "outputId": "eea336cf-d981-41e8-a672-45fbd20e1ce4"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "tflite_model_file = pathlib.Path('/content/model.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3380268"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "rWBNH-DQ-NYg",
        "outputId": "43d6faa8-b129-4316-be33-42fec66fea62"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(tflite_model_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3135340d-32ac-44ad-b56a-45571839d5d2\", \"model.tflite\", 3380268)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}